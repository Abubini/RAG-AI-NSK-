[
  {
    "page_content": "File system\n\nFile concept\n\ncomputers use various types of non-volatile storage devices (like HDDs, SSDs, tapes, etc.) to store data, and the operating system provides a consistent, logical view of this storage by using files. A file is a named collection of related information and is the smallest unit in which data can be stored on secondary storage. Files can contain different types of data such as text, programs, images, or system information and their structure depends on the type of content. The operating system abstracts physical storage through the use of files, making data storage and retrieval more manageable for users and applications\n\n\n\nFile attribute",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 0,
      "chunk_id": 0,
      "chunk_size": 669
    }
  },
  {
    "page_content": "File attribute\n\nA file is identified by a human-readable name, making it easy for users to reference, regardless of who created or uses it. Once created, a file becomes independent of its origin and can be copied or shared across systems while retaining its name. Additionally, files have various attributes such as name, type, location, size, access permissions, timestamps, and unique identifiers that help the operating system manage, protect, and track the file. Some modern file systems also include extended attributes like character encoding and security features.\n\n\n\n\tName The symbolic file name is the only information kept in human readable form.\n\n\tIdentifie This unique tag, usually a number, identifies the file within the file system it is the non-human-readable name for the file.\n\n\tType This information is needed for systems that support different types of files.\n\n\n\n\tLocation This information is a pointer to a device and to the location of the file on that device",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 655,
      "chunk_id": 1,
      "chunk_size": 981
    }
  },
  {
    "page_content": "Type This information is needed for systems that support different types of files.\n\n\n\n\tLocation This information is a pointer to a device and to the location of the file on that device\n\n\tSize The current size of the file (in bytes, words, or blocks) and possibly the maximum allowed size are included in this attribute.\n\n\tProtection Access-control information determines who can do reading, writing, executing, and so on.\n\n\tTimestamps and user identification This information may be kept for creation, last modification, and last use. These data can be useful for protection, security, and usage monitoring.\n\n\n\n\n\nFile operation\n\nA file is an abstract data type. To define a file properly, we need to consider the operations that can be performed on files. The operating system can provide system calls to create, write, read, reposition, delete and truncate files.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 1452,
      "chunk_id": 2,
      "chunk_size": 864
    }
  },
  {
    "page_content": "Creating a file Two steps are necessary to create a file. First, space in the file system must be found for the file. Second, an entry for the new file must be made in the directory.\n\n\tWriting a file To write a file, we make a system call specifying both the name of the file and the information to be written to the file. Given the name of the file the system searches the directory to find the file’s location. The system must keep a write pointer to the location in the file where the next write is to take place. The write pointer must be updated whenever a write occurs.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 2319,
      "chunk_id": 3,
      "chunk_size": 575
    }
  },
  {
    "page_content": "Reading a file To read from a file, we use a system call that specifies the name of the file and where (in memory) the next block of the file should be put. Again, the directory is searched for the associated entry, and the system needs to keep a read pointer to the location in the file where the next read is to take place. Once the read has taken place, the read pointer is updated. Because a process is usually either reading from or writing to a file, the current operation location can be kept as a per-process current f ile-position pointer. Both the read and write operations use this same pointer, saving space and reducing system complexity.\n\n\tRepositioning within a file The directory is searched for the appropriate entry, and the current-file-position pointer is repositioned to a given value. Repositioning within a file need not involve any actual I/O. This file operation is also known as a file seek.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 2897,
      "chunk_id": 4,
      "chunk_size": 917
    }
  },
  {
    "page_content": "Deleting a file To delete a file, we search the directory for the named file. Having found the associated directory entry, we release all file space, so that it can be reused by other files, and erase the directory entry\n\n\tTruncating a file The user may want to erase the contents of a file but keep its attributes. Rather than forcing the user to delete the file and then re create it, this function allows all attributes to remain unchanged—except for file length—but lets the file be reset to length zero and its file space released.\n\n\tFile pointer On systems that do not include a file offset as part of the read() and write() system calls, the system must track the last read write location as a current-file-position pointer. This pointer is unique to each process operating on the file and therefore must be kept separate from the on-disk file attributes.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 3819,
      "chunk_id": 5,
      "chunk_size": 862
    }
  },
  {
    "page_content": "File-open count As files are closed, the operating system must reuse its open-file table entries, or it could run out of space in the table. Multiple processes may have opened a file, and the system must wait for the last file to close before removing the open-file table entry. The file-open count tracks the number of opens and closes and reaches zero on the last close. The system can then remove the entry.\n\n\tDisk location of the file Most file operations require the system to modify data within the file. The information needed to locate the file on disk is kept in memory so that the system does not have to read it from disk for each operation.\n\n\tAccess rights Each process opens a file in an access mode. This information is stored on the per process table so the operating system can allow or deny subsequent I/O requests.\n\n\n\nFile types",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 4684,
      "chunk_id": 6,
      "chunk_size": 846
    }
  },
  {
    "page_content": "Access rights Each process opens a file in an access mode. This information is stored on the per process table so the operating system can allow or deny subsequent I/O requests.\n\n\n\nFile types\n\nthe importance of file types in operating systems and how they help the system and applications interact appropriately with files. A common way to indicate a file's type is by using a file extension (e.g., .docx, .exe, .java). These extensions help identify what kind of file it is and what operations can be performed on it. While some operating systems rely on extensions to recognize file types, others treat them as hints for applications. Recognizing file types helps prevent errors, such as trying to read binary files as text, and allows programs to find and work with the files they expect.\n\n\n\nFile structure",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 5339,
      "chunk_id": 7,
      "chunk_size": 809
    }
  },
  {
    "page_content": "File structure\n\nfile types can define a file's internal structure, which is necessary for the operating system and applications to properly read and use the file. While supporting multiple file structures can make the OS more functional, it also increases complexity and size. To avoid this, many systems (like UNIX and Windows) keep file structures minimal and treat files simply as byte sequences, leaving structure interpretation to applications. However, the OS must still recognize certain essential file types, like executables, to function properly.\n\n\n\nInternal file structure",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 6134,
      "chunk_id": 8,
      "chunk_size": 583
    }
  },
  {
    "page_content": "Internal file structure\n\nManaging file data on disk involves dealing with differences between logical data organization and the physical storage structure of disks. Disks perform input/output operations in fixed-size units called blocks, which are determined by the hardware’s sector size (e.g., 512 bytes per block). However, the logical records that applications or users work with—such as lines of text or individual bytes— often do not align perfectly with these fixed block sizes. As a result, the operating system or application must pack multiple logical records into physical blocks to make efficient use of disk space and ensure correct data access.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 6694,
      "chunk_id": 9,
      "chunk_size": 658
    }
  },
  {
    "page_content": "For instance, UNIX treats files simply as streams of bytes, where each byte is addressable by its offset from the beginning of the file. This provides flexibility and simplicity, allowing any program to access any part of a file without needing to worry about record boundaries. The operating system handles packing and unpacking of bytes into physical disk blocks behind the scenes, allowing developers to focus on the logical structure of their data rather than physical disk limitations.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 7354,
      "chunk_id": 10,
      "chunk_size": 490
    }
  },
  {
    "page_content": "However, this method introduces internal fragmentation, where the last block of a file may not be fully used. Since disk space is always allocated in whole blocks, any unused portion of the last block represents wasted space. For example, if a file is 1,949 bytes and the block size is 512 bytes, the system will allocate 2,048 bytes (four full blocks), leaving 99 bytes unused. This waste increases as block sizes grow, creating a trade-off between larger block sizes (which may improve performance) and efficiency of space usage.\n\nthe operating system must bridge the gap between how data is logically organized and how it is physically stored. It does so by translating logical records into physical blocks and managing the resulting overhead, such as internal fragmentation. While this introduces some inefficiency, especially with larger block sizes, it is a necessary part of making file systems practical and efficient for a wide variety of applications and data types.\n\n\n\nAccess methods",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 7846,
      "chunk_id": 11,
      "chunk_size": 994
    }
  },
  {
    "page_content": "Access methods\n\nSequential access\n\nThe simplest access method is sequential access. Information in the file is processed in order, one record after the other. This mode of access is by far the most common; for example, editors and compilers usually access files in this fashion.\n\nReads and writes make up the bulk of the operations on a file. A read operation—read next() reads the next portion of the file and automatically advances a file pointer, which tracks the I/O location. Similarly, the write operation write next() appends to the end of the file and advances to the end of the newly written material (the new end of file). Such a file can be reset to the beginning, and on some systems a program may be able to skip forward or backward n records for some integer n perhaps only for n = 1. Sequential access,\n\n\n\n\n\n\n\n\n\nSequential access file",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 8826,
      "chunk_id": 12,
      "chunk_size": 849
    }
  },
  {
    "page_content": "Sequential access file\n\nwhich is depicted in the Figure above is based on a tape model of a file and works as well on sequential-access devices as it does on random-access ones.\n\n\n\nDirect access\n\nthe direct-access (or relative access) method for file systems, which allows programs to read or write fixed-length records in any order, unlike sequential access which processes data in a specific sequence. Direct access is especially useful for applications like databases or reservation systems, where fast, random access to specific records is essential. With this method, file operations are based on block numbers that reference the position of data relative to the file’s start, rather than its physical location on disk. This abstraction gives the operating system flexibility in file placement and helps manage security.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 9653,
      "chunk_id": 13,
      "chunk_size": 825
    }
  },
  {
    "page_content": "Some systems support only sequential or direct access, while others require declaring the access type when a file is created. Although sequential access can be simulated on direct-access files easily, the reverse is inefficient. Overall, direct access enhances performance for data-heavy applications that need quick, targeted retrieval of information.\n\n\n\nDirectory structure\n\nThe directory can be viewed as a symbol table that translates file names into their file control blocks. If we take such a view, we see that the directory itself can be organized in many ways. The organization must allow us to insert entries, to delete entries, to search for a named entry, and to list all the entries in the directory. When considering a particular directory structure we need to keep in mind the operations that are to be performed on a directory:",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 10480,
      "chunk_id": 14,
      "chunk_size": 843
    }
  },
  {
    "page_content": "Search for a file We need to be able to search a directory structure to find the entry for a particular file. Since files have symbolic names and similar names may indicate a relationship among files, we may want to be able to find all files whose names match a particular pattern.\n\n\tCreate a file New files need to be created and added to the directory.\n\n\tDelete a file When a file is no longer needed we want to be able to remove it from the directory. Note a delete leaves a hole in the directory structure and the file system may have a method to defragement the directory structure.\n\n\t\t\tList a directory We need to be able to list the files in a directory and the contents of the directory entry for each file in the list.\n\n\tRename a file Because the name of a file represents its contents to its users, we must be able to change the name when the contents or use of the file changes. Renaming a file may also allow its position within the directory structure to be changed.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 11326,
      "chunk_id": 15,
      "chunk_size": 979
    }
  },
  {
    "page_content": "Traverse the file system We may wish to access every directory and every file within a directory structure. For reliability, it is a good idea to save the contents and structure of the entire file system at regular intervals. Often, we do this by copying all files to magnetic tape other secondary storage or across a network to another system or the cloud. This technique provides a backup copy in case of system failure. In addition, if a file is no longer in use the file can be copied the backup target and the disk space of that file released for reuse by another file.\n\n\n\nSingle level directory",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 12308,
      "chunk_id": 16,
      "chunk_size": 600
    }
  },
  {
    "page_content": "Single level directory\n\nThe simplest directory structure is the single-level directory. All files are contained in the same directory, which is easy to support and understand A single- level directory has significant limitations, however, when the number of files increases or when the system has more than one user. Since all files are in the same directory, they must have unique names. If two users call their data file test.txt, then the unique-name rule is violated\n\n\n\n\n\nSingle level directory\n\n\n\n\n\nTwo level directory",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 12886,
      "chunk_id": 17,
      "chunk_size": 523
    }
  },
  {
    "page_content": "Single level directory\n\n\n\n\n\nTwo level directory\n\nAs we have seen a single level directory often leads to confusion of file names among different users. But In a two-level directory structure each user has a separate User File Directory (UFD), and all UFDs are listed in a Master File Directory (MFD). This structure helps prevent filename conflicts between users but limits collaboration, as it isolates user files. To allow access to another user's file, a user must know the full path name (e.g., /user b/test.txt), combining both the username and filename.\n\nDifferent operating systems use different file naming conventions. For example, Windows uses volume letters (C:\\user b\\test.txt), while UNIX/Linux uses hierarchical paths (/u/pgalvin/test). Some systems (like OpenVMS) include volume, directory, and version information in file names.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 13362,
      "chunk_id": 18,
      "chunk_size": 844
    }
  },
  {
    "page_content": "For system files (e.g., loaders or compilers), storing copies in every UFD is inefficient. Instead, a special directory stores these files, and the OS searches user directories first, then this system directory, based on a search path. The search path can be customized, allowing flexible file and command location resolution, commonly seen in UNIX and Windows systems.\n\n\n\n\n\nTwo level directory structure\n\nTree structured directories\n\nA tree-structured directory extends the two-level directory into a hierarchy of arbitrary depth, allowing users to create subdirectories to organize files logically. The structure starts with a root directory, and each file has a unique path name—either absolute (starting from root) or relative (from the current directory).\n\nEach process typically has a current directory, set at login and inherited by subprocesses. Users can change this directory to access different files more easily.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 14210,
      "chunk_id": 19,
      "chunk_size": 924
    }
  },
  {
    "page_content": "Each process typically has a current directory, set at login and inherited by subprocesses. Users can change this directory to access different files more easily.\n\nDirectories are special files with entries marked as either files or subdirectories, managed using system calls. This model provides flexibility, allowing logical grouping of files (e.g., separating source code and binaries).\n\nDeleting directories can follow two policies:\n\n\n\n\tOnly allow deletion if empty, requiring manual file removal.\n\n\tRecursive deletion, as in UNIX's rm -r, which removes all contents but risks accidental data loss.\n\nUsers can access other users' files by specifying full path names, supporting both file organization and file sharing.\n\n\n\nAcyclic graph directories\n\nAn acyclic graph directory structure is an extension of the tree structure that allows file and directory sharing across multiple locations in the file system without duplication.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 14972,
      "chunk_id": 20,
      "chunk_size": 932
    }
  },
  {
    "page_content": "An acyclic graph directory structure is an extension of the tree structure that allows file and directory sharing across multiple locations in the file system without duplication.\n\n\t\tPurpose: Enables multiple users or directories to share the same file or subdirectory, avoiding unnecessary duplication and ensuring changes are reflected everywhere.\n\n\tStructure:\n\n\tA tree prohibits sharing.\n\n\tAn acyclic graph (no cycles) allows files/subdirectories to exist in multiple directories.\n\n\n\n\tImplementation Methods:\n\n\tLinks (symbolic or hard) point to the actual file or directory.\n\n\tSymbolic links (soft): Store the path to the original file; may break if the target is deleted.\n\n\tHard links: Share the same inode and use a reference count to manage deletion.\n\n\tDuplicate entries (not recommended): Cause consistency issues when a file is modified.\n\n\tChallenges:\n\n\tMultiple path names to the same file (aliasing problem).\n\n\tTraversal issues during backups or system scans.\n\n\tDeletion complications:",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 15725,
      "chunk_id": 21,
      "chunk_size": 995
    }
  },
  {
    "page_content": "Challenges:\n\n\tMultiple path names to the same file (aliasing problem).\n\n\tTraversal issues during backups or system scans.\n\n\tDeletion complications:\n\n\tIf one user deletes a file, others may be left with dangling pointers.\n\n\tReference counting is used (as in UNIX) to delete a file only when all references are removed.\n\n\tDesign Considerations:\n\n\t\t\t\t\t\t\t\t\t\tSome\tsystems\t(for\tsimplicity\tand\tsafety)\tdo\tnot\tallow\tshared directories or links.\n\n\tProper management of links and deletion policies is crucial to maintain file system integrity.\n\nAn acyclic graph directory offers flexibility for sharing but adds complexity in managing references, updates, and deletions. Systems like UNIX manage this using reference counts and links while avoiding cycles to maintain structure.\n\n\n\n\n\nAcyclic-graph directory structure\n\n\n\n\n\nGeneral graph directory",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 16573,
      "chunk_id": 22,
      "chunk_size": 836
    }
  },
  {
    "page_content": "Acyclic-graph directory structure\n\n\n\n\n\nGeneral graph directory\n\nAn acyclic graph directory structure is designed to allow file and directory sharing while avoiding cycles to maintain simplicity and performance. However, introducing links can unintentionally create cycles, which cause serious issues.\n\n\tAcyclic vs. Cyclic Structure:\n\n\tA tree structure is naturally acyclic.\n\n\tAdding links can turn it into a graph, and if not managed carefully, cycles can form.\n\n\tProblems Caused by Cycles:\n\n\tInfinite loops during file searches or traversal due to re-entering the same directories.\n\n\tIncorrect deletion handling because files in a cycle might still show non- zero reference counts even if they're no longer accessible.\n\n\n\n\tGarbage Collection Requirement:\n\n\tIf cycles exist, reference counts alone are unreliable.\n\n\tGarbage collection (mark-and-sweep) is needed to identify and delete unreachable files.\n\n\tHowever, garbage collection is slow and rarely used in disk-based systems.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 17347,
      "chunk_id": 23,
      "chunk_size": 980
    }
  },
  {
    "page_content": "Garbage collection (mark-and-sweep) is needed to identify and delete unreachable files.\n\n\tHowever, garbage collection is slow and rarely used in disk-based systems.\n\n\tCycle Prevention Strategies:\n\n\tUse cycle detection algorithms (costly in disk-based graphs).\n\n\tA practical approach is to ignore links during traversal, which avoids cycles and overhead.\n\nTo keep directory management efficient and safe, acyclic structures are preferred. Allowing cycles introduces complexity, risks infinite loops, and necessitates expensive garbage collection. Thus, systems must carefully prevent cycles when implementing file sharing via links.\n\n\n\n\n\nGeneral graph directory\n\n\n\nProtection",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 18163,
      "chunk_id": 24,
      "chunk_size": 674
    }
  },
  {
    "page_content": "General graph directory\n\n\n\nProtection\n\nWhen information is stored in a computer system, we want to keep it safe from physical damage (the issue of reliability) and improper access (the issue of protection). Reliability is generally provided by duplicate copies of files.Manycomput ers have systems programs that automatically (or through computer-operator intervention) copy disk files to tape at regular intervals (once per day or week or month) to maintain a copy should a file system be accidentally destroyed. File systems can be damaged by hardware problems (such as errors in reading or writing), power surgesor failures, head crashes, dirt, temperature extremes, and vandalism. Files may be deleted accidentally. Bugs in the file-system soft ware can also cause file contents to be lost.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 18800,
      "chunk_id": 25,
      "chunk_size": 794
    }
  },
  {
    "page_content": "Protection can be provided in many ways. For a laptop system running a modern operating system, we might provide protection by requiring a user nameandpasswordauthentication to access it, encrypting the secondary stor age so even someone opening the laptop and removing the drive would have a difficult time accessing its data, and firewalling network access so that when it is in use it is difficult to break in via its network connection. In multiuser system, even valid access of the system needs more advanced mechanisms to allow only valid access of the data.\n\n\n\nTypes of access",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 19596,
      "chunk_id": 26,
      "chunk_size": 583
    }
  },
  {
    "page_content": "Types of access\n\nThe need to protect files is a direct result of the ability to access files. Systems that do not permit access to the files of other users do not need protection. Thus, wecould providecomplete protection by prohibiting access. Alternatively, we could provide free access with no protection. Both approaches are too extreme for general use. What is needed is controlled access. Protection mechanisms provide controlled access by limiting the types of f ile access that can be made. Access is permitted or denied depending on several factors, one of which is the type of access requested. Several different types of operations may be controlled:\n\n\n\n\tRead Read from the file.\n\n\tWrite Write or rewrite the file.\n\n\tExecute Load the file into memory and execute it.\n\n\tAppend Write newinformation at the end of the file.\n\n\tDelete Delete the file and free its space for possible reuse.\n\n\tList List the name and attributes of the file.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 20164,
      "chunk_id": 27,
      "chunk_size": 943
    }
  },
  {
    "page_content": "Append Write newinformation at the end of the file.\n\n\tDelete Delete the file and free its space for possible reuse.\n\n\tList List the name and attributes of the file.\n\n\tAttribute change Changing the attributes of the file.\n\n\n\nAccess control\n\nThe main idea is that file and directory access in operating systems is controlled based on user identity, using Access Control Lists (ACLs) and simplified user classifications (Owner, Group, Other) to manage permissions efficiently.\n\n\tAccess Control Lists (ACLs):\n\n\tEach file/directory can have an ACL specifying which users have which types of access (read, write, execute).\n\n\tOffers fine-grained control but can be long and hard to manage.\n\n\tSimplified Access Scheme:\n\n\tMost systems simplify by using three user classes:\n\n\tOwner: The file creator.\n\n\tGroup: A set of users with shared access.\n\n\tOther: All remaining users.\n\n\tEach class has read (r), write (w), and execute (x) permissions.\n\n\tCombining ACLs with User Classes:",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 20943,
      "chunk_id": 28,
      "chunk_size": 967
    }
  },
  {
    "page_content": "Group: A set of users with shared access.\n\n\tOther: All remaining users.\n\n\tEach class has read (r), write (w), and execute (x) permissions.\n\n\tCombining ACLs with User Classes:\n\n\tModern systems like UNIX and Solaris use the owner/group/other model by default, with ACLs added only when finer control is needed.\n\n\tExample: A project team can be a group, while temporary access for an outsider can be managed via ACLs.\n\n\n\n\tImplementation Details:\n\n\tUNIX: Uses 9 permission bits (rwx for each class), with optional ACLs indicated by a “+” sign in listings.\n\n\tSolaris: Uses commands like setfacl and getfacl.\n\n\tWindows: Uses a GUI to manage ACLs and permissions.\n\n\tPermission Conflicts:\n\n\tWhen ACLs and standard group permissions conflict, ACLs take precedence, as they provide more specific rules.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 21736,
      "chunk_id": 29,
      "chunk_size": 792
    }
  },
  {
    "page_content": "Windows: Uses a GUI to manage ACLs and permissions.\n\n\tPermission Conflicts:\n\n\tWhen ACLs and standard group permissions conflict, ACLs take precedence, as they provide more specific rules.\n\nACLs provide flexible and detailed control over file access, while user classifications (owner, group, other) simplify standard permission settings. Most systems combine both approaches for efficiency and fine-tuned security, with ACLs overriding default permissions when conflicts arise.\n\n\n\nOther protection approaches",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 22341,
      "chunk_id": 30,
      "chunk_size": 508
    }
  },
  {
    "page_content": "Another approach to the protection problem is to associate a password with each file. Just as access to the computer system is often controlled by a password access to each file can be controlled in the same way. If the passwords are chosen randomly and changed often, this scheme may be effective in limiting access to a file. The use of passwords has a few disadvantages however. First, the number of passwords that a user needs to remember may become large, making the scheme impractical. Second, if only one password is used for all the files then once it is discovered all files are accessible protection is on an all-or-none basis. Some systems allow a user to associate a password with a subdirectory rather than with an individual file to address this problem. In a multilevel directory structure, we need to protect not only individual files but also collections of files in subdirectories; that is, we need to provide a mechanism for directory protection. The directory operations that",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 22851,
      "chunk_id": 31,
      "chunk_size": 995
    }
  },
  {
    "page_content": "we need to protect not only individual files but also collections of files in subdirectories; that is, we need to provide a mechanism for directory protection. The directory operations that must be protected are somewhat different from the file operations. We want to control the creation and deletion of files in a directory. In addition, we probably want to control whether a user can determine the",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 23657,
      "chunk_id": 32,
      "chunk_size": 400
    }
  },
  {
    "page_content": "existence of a file in a directory. Sometimes knowledge of the existence and name of a file is significant in itself.\n\nThus, listing the contents of a directory must be a protected operation.\n\nSimilarly, if a path name refers to a file in a directory, the user must be allowed access to both the directory and the file. In systems where files may have\n\nnumerous path names (such as acyclic and general graphs), a given user may have different access rights to a particular file, depending on the path name used.\n\n\n\nMemory mapped files",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 24061,
      "chunk_id": 33,
      "chunk_size": 534
    }
  },
  {
    "page_content": "numerous path names (such as acyclic and general graphs), a given user may have different access rights to a particular file, depending on the path name used.\n\n\n\nMemory mapped files\n\nThere is one other method of accessing files, and it is very commonly used. Consider a sequential read of a file on disk using the standard system calls open(), read(),andwrite(). Each file access requires a system call and disk access. Alternatively, we can use the virtual memory techniques in to treat file I/O as routine memory accesses. This approach, known as memory mapping a file, allows a part of the virtual address space to be logically associated with the file. As we shall see, this can lead to significant performance increases.\n\nBasic mechanism",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 24414,
      "chunk_id": 34,
      "chunk_size": 742
    }
  },
  {
    "page_content": "Basic mechanism\n\nMemory-mapped files are a powerful mechanism used by modern operating systems to optimize file access and enable interprocess communication. Instead of reading and writing files through traditional system calls like read() and write(), memory mapping allows a file to be directly mapped into the virtual memory space of a process. This approach not only improves performance by eliminating the overhead of frequent system calls but also simplifies file manipulation by treating file content as if it were part of the main memory.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 25141,
      "chunk_id": 35,
      "chunk_size": 546
    }
  },
  {
    "page_content": "When a file is memory-mapped, the operating system links disk blocks to pages in virtual memory. The first time a part of the file is accessed, a page fault occurs, prompting the OS to load that portion of the file from disk into a physical memory page. Subsequent accesses are handled like ordinary memory operations. Writes to the file, however, are not immediately saved to disk. Instead, they are temporarily stored in memory and only written back to disk either when the file is closed or under memory pressure, ensuring data is not lost.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 25689,
      "chunk_id": 36,
      "chunk_size": 543
    }
  },
  {
    "page_content": "Different operating systems implement memory mapping in different ways. For instance, Solaris automatically memory-maps files, whether they are accessed through explicit memory-mapping system calls (like mmap()) or through traditional file access methods. If accessed through standard system calls, Solaris maps the file to the kernel address space, while memory-mapped files are placed in the process address space. In either case, the file I/O benefits from the speed and efficiency of memory operations.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 26234,
      "chunk_id": 37,
      "chunk_size": 506
    }
  },
  {
    "page_content": "An important advantage of memory-mapped files is their ability to enable data sharing between processes. When multiple processes map the same file, they share the same physical memory pages, so changes made by one process can be instantly seen by the others. This sharing mechanism can be controlled using mutual exclusion methods to ensure consistency and synchronization. Additionally, copy-on-write can be used to allow multiple processes to share read- only access while creating separate memory copies if any process attempts to modify the data.\n\nBeyond file access, memory mapping also plays a vital role in interprocess communication (IPC). Shared memory segments are often created by memory- mapping files into the address space of communicating processes. This technique provides an efficient way for processes to exchange information by reading and writing to a common memory region without the need for slower I/O operations.",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 26744,
      "chunk_id": 38,
      "chunk_size": 936
    }
  },
  {
    "page_content": "memory-mapped files streamline file access and enhance performance by reducing system call overhead and enabling direct memory manipulation. They also provide a foundation for efficient shared memory, facilitating fast and simple communication between processes. By integrating file I/O and memory management, memory mapping is a key feature in modern operating systems that supports both performance optimization and process collaboration.\n\n\n\nShared memory in the window API\n\nThe general outline for creating a region of shared memory using memory mappedfiles in the Windows API involves first creating a fil mapping for the file to be mapped and then establishing a view of the mapped file in a process’s virtual address space. A second process can then open and create a view of the mapped file in its virtual address space. The mapped file represents the shared- memory object that will enable communication to take place between the\n\nprocesses",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 27682,
      "chunk_id": 39,
      "chunk_size": 948
    }
  },
  {
    "page_content": "processes\n\nWe next illustrate these steps in more detail. In this example, a producer process first creates a shared-memory object using the memory-mapping fea\n\n\n\ntures available in the Windows API. The producer then writes a message to shared memory. After that a consumer process opens a mapping to the shared memory object and reads the message written by the consumer\n\n\n\n\tMemory mapped files\tshared memory using memory mapped I/O\n\n\n\nReferences\n\nOperating system concepts tenth edition by ABRAHAM SILBERSCHATZ, PETER BAER GALVIN, GREG GAGNE\n\nOperating system concepts ninth edition by ABRAHAM SILBERSCHATZ, PETER BAER GALVIN, GREG GAGNE\n\nModern operating system fourth edition by ANDREW S. TANENBAUM HERBERT BOS\n\ninternet\n\n\n\n3 | P a g e\n\n3 | P a g e\n\n\n\n10 | P a g e\n\n10 | P a g e\n\n\n\n11 | P a g e\n\n11 | P a g e\n\n\n\n20 | P a g e\n\n20 | P a g e\n\n\n\n21 | P a g e\n\n21 | P a g e",
    "metadata": {
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/test.docx",
      "start_index": 28621,
      "chunk_id": 40,
      "chunk_size": 872
    }
  },
  {
    "page_content": "File system\n\nFile concept\n\ncomputers use various types of non-volatile storage devices (like HDDs, SSDs, tapes, etc.) to store data, and the operating system provides a consistent, logical view of this storage by using files. A file is a named collection of related information and is the smallest unit in which data can be stored on secondary storage. Files can contain different types of data such as text, programs, images, or system information and their structure depends on the type of content. The operating system abstracts physical storage through the use of files, making data storage and retrieval more manageable for users and applications\n\nFile attribute",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 0,
      "chunk_id": 0,
      "chunk_size": 667
    }
  },
  {
    "page_content": "File attribute\n\nA file is identified by a human-readable name, making it easy for users to reference, regardless of who created or uses it. Once created, a file becomes independent of its origin and can be copied or shared across systems while retaining its name. Additionally, files have various attributes such as name, type, location, size, access permissions, timestamps, and unique identifiers that help the operating system manage, protect, and track the file. Some modern file systems also include extended attributes like character encoding and security features.\n\nName The symbolic file name is the only information kept in human readable form.\n\nIdentifie This unique tag, usually a number, identifies the file within the file system it is the non-human-readable name for the file.\n\nType This information is needed for systems that support different types of files.\n\n3 | P a g e\n\n\n\nLocation This information is a pointer to a device and to the location of the file on that device",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 653,
      "chunk_id": 1,
      "chunk_size": 988
    }
  },
  {
    "page_content": "Type This information is needed for systems that support different types of files.\n\n3 | P a g e\n\n\n\nLocation This information is a pointer to a device and to the location of the file on that device\n\nSize The current size of the file (in bytes, words, or blocks) and possibly the maximum allowed size are included in this attribute.\n\nProtection Access-control information determines who can do reading,\n\nwriting, executing, and so on.\n\nTimestamps and user identification This information may be kept for\n\ncreation, last modification, and last use. These data can be useful for protection, security, and usage monitoring.\n\n4 | P a g e\n\n\n\nFile operation\n\nA file is an abstract data type. To define a file properly, we need to consider the operations that can be performed on files. The operating system can provide system calls to create, write, read, reposition, delete and truncate files.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 1445,
      "chunk_id": 2,
      "chunk_size": 886
    }
  },
  {
    "page_content": "Creating a file Two steps are necessary to create a file. First, space in the file system must be found for the file. Second, an entry for the new file must be made in the directory.\n\nWriting a file To write a file, we make a system call specifying both the name of the file and the information to be written to the file. Given the name of the file the system searches the directory to find the file’s location. The system must keep a write pointer to the location in the file where the next write is to take place. The write pointer must be updated whenever a write occurs.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 2333,
      "chunk_id": 3,
      "chunk_size": 574
    }
  },
  {
    "page_content": "Reading a file To read from a file, we use a system call that specifies the name of the file and where (in memory) the next block of the file should be put. Again, the directory is searched for the associated entry, and the system needs to keep a read pointer to the location in the file where the next read is to take place. Once the read has taken place, the read pointer is updated. Because a process is usually either reading from or writing to a file, the current operation location can be kept as a per-process current f ile-position pointer. Both the read and write operations use this same pointer, saving space and reducing system complexity.\n\nRepositioning  within  a  file  The  directory  is  searched  for  the\n\nappropriate entry, and the current-file-position pointer is repositioned to a given value. Repositioning within a file need not involve any actual I/O. This file operation is also known as a file seek.\n\n5 | P a g e",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 2909,
      "chunk_id": 4,
      "chunk_size": 939
    }
  },
  {
    "page_content": "5 | P a g e\n\n\n\nDeleting a file To delete a file, we search the directory for the named file. Having found the associated directory entry, we release all file space, so that it can be reused by other files, and erase the directory entry\n\nTruncating a file The user may want to erase the contents of a file but keep its attributes. Rather than forcing the user to delete the file and then  re  create  it,  this  function  allows  all  attributes  to  remain unchanged—except for file length—but lets the file be reset to length zero and its file space released.\n\nFile pointer On systems that do not include a file offset as part of the read() and write() system calls, the system must track the last read write location as a current-file-position pointer. This pointer is unique to each process operating on the file and therefore must be kept separate from the on-disk file attributes.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 3837,
      "chunk_id": 5,
      "chunk_size": 885
    }
  },
  {
    "page_content": "File-open count As files are closed, the operating system must reuse its open-file table entries, or it could run out of space in the table. Multiple processes may have opened a file, and the system must wait for the last file to close before removing the open-file table entry. The file-open count tracks the number of opens and closes and reaches zero on the last close. The system can then remove the entry.\n\nDisk location of the file Most file operations require the system to modify data within the file. The information needed to locate the file on disk is kept in memory so that the system does not have to read it from disk for each operation.\n\nAccess rights Each process opens a file in an access mode. This information is stored on the per process table so the operating system can allow or deny subsequent I/O requests.\n\n6 | P a g e\n\n\n\nFile types",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 4724,
      "chunk_id": 6,
      "chunk_size": 857
    }
  },
  {
    "page_content": "6 | P a g e\n\n\n\nFile types\n\nthe importance of file types in operating systems and how they help the system and applications interact appropriately with files. A common way to indicate a file's type is by using a file extension (e.g., .docx, .exe, .java). These extensions help identify what kind of file it is and what operations can be performed on it. While some operating systems rely on extensions to recognize file types, others treat them as hints for applications. Recognizing file types helps prevent errors, such as trying to read binary files as text, and allows programs to find and work with the files they expect.\n\nFile structure",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 5556,
      "chunk_id": 7,
      "chunk_size": 641
    }
  },
  {
    "page_content": "File structure\n\nfile types can define a file's internal structure, which is necessary for the operating system and applications to properly read and use the file. While supporting multiple file structures can make the OS more functional, it also increases complexity and size. To avoid this, many systems (like UNIX and Windows) keep file structures minimal and treat files simply as byte sequences, leaving structure interpretation to applications. However, the OS must still recognize certain essential file types, like executables, to function properly.\n\n7 | P a g e\n\n\n\nInternal file structure",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 6183,
      "chunk_id": 8,
      "chunk_size": 596
    }
  },
  {
    "page_content": "7 | P a g e\n\n\n\nInternal file structure\n\nManaging file data on disk involves dealing with differences between logical data organization and the physical storage structure of disks. Disks perform input/output operations in fixed-size units called blocks, which are determined by the hardware’s sector size (e.g., 512 bytes per block). However, the logical records that applications or users work with—such as lines of text or individual bytes— often do not align perfectly with these fixed block sizes. As a result, the operating system or application must pack multiple logical records into physical blocks to make efficient use of disk space and ensure correct data access.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 6741,
      "chunk_id": 9,
      "chunk_size": 673
    }
  },
  {
    "page_content": "For instance, UNIX treats files simply as streams of bytes, where each byte is addressable by its offset from the beginning of the file. This provides flexibility and simplicity, allowing any program to access any part of a file without needing to worry about record boundaries. The operating system handles packing and unpacking  of  bytes  into  physical  disk  blocks  behind  the  scenes,  allowing developers to focus on the logical structure of their data rather than physical disk limitations.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 7416,
      "chunk_id": 10,
      "chunk_size": 500
    }
  },
  {
    "page_content": "However, this method introduces internal fragmentation, where the last block of a file may not be fully used. Since disk space is always allocated in whole blocks, any unused portion of the last block represents wasted space. For example, if a file is 1,949 bytes and the block size is 512 bytes, the system will allocate 2,048 bytes (four full blocks), leaving 99 bytes unused. This waste increases as block sizes grow, creating a trade-off between larger block sizes (which may improve performance) and efficiency of space usage.\n\nthe operating system must bridge the gap between how data is logically organized and how it is physically stored. It does so by translating logical records into physical blocks and managing the resulting overhead, such as internal fragmentation. While this introduces some inefficiency, especially with larger block sizes, it is a necessary part of making file systems practical and efficient for a wide variety of applications and data types.\n\n8 | P a g e",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 7918,
      "chunk_id": 11,
      "chunk_size": 989
    }
  },
  {
    "page_content": "8 | P a g e\n\n\n\nAccess methods\n\nSequential access\n\nThe simplest access method is sequential access. Information in the file is processed in order, one record after the other. This mode of access is by far the most common; for example, editors and compilers usually access files in this fashion.\n\nReads and writes make up the bulk of the operations on a file. A read operation—read next() reads the next portion of the file and automatically advances a file pointer, which tracks the I/O location. Similarly, the write operation write next() appends to the end of the file and advances to the end of the newly written material (the new end of file). Such a file can be reset to the beginning, and on some systems a program may be able to skip forward or backward n records for some integer n perhaps only for n = 1. Sequential access,\n\nSequential access file",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 8896,
      "chunk_id": 12,
      "chunk_size": 856
    }
  },
  {
    "page_content": "Sequential access file\n\nwhich is depicted in the Figure above is based on a tape model of a file and works as well on sequential-access devices as it does on random-access ones.\n\n9 | P a g e\n\n\n\nDirect access\n\nthe direct-access (or relative access) method for file systems, which allows programs to read or write fixed-length records in any order, unlike sequential access which processes data in a specific sequence. Direct access is especially useful for applications like databases or reservation systems, where fast, random access to specific records is essential. With this method, file operations are based on block numbers that reference the position of data relative to the file’s start, rather than its physical location on disk. This abstraction gives the operating system flexibility in file placement and helps manage security.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 9730,
      "chunk_id": 13,
      "chunk_size": 838
    }
  },
  {
    "page_content": "Some systems support only sequential or direct access, while others require declaring the access type when a file is created. Although sequential access can be simulated on direct-access files easily, the reverse is inefficient. Overall, direct access enhances  performance for data-heavy applications that need quick, targeted retrieval of information.\n\n10 | P a g e\n\n\n\nDirectory structure\n\nThe directory can be viewed as a symbol table that translates file names into their file control blocks. If we take such a view, we see that the directory itself can be organized in many ways. The organization must allow us to insert entries, to delete entries, to search for a named entry, and to list all the entries in the directory. When considering a particular directory structure we need to keep in mind the operations that are to be performed on a directory:",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 10570,
      "chunk_id": 14,
      "chunk_size": 858
    }
  },
  {
    "page_content": "Search for a file We need to be able to search a directory structure to find the entry for a particular file. Since files have symbolic names and similar names may indicate a relationship among files, we may want to be able to find all files whose names match a particular pattern.\n\nCreate a file New files need to be created and added to the directory.\n\nDelete a file When a file is no longer needed we want to be able to remove it from the directory. Note a delete leaves a hole in the directory structure and the file system may have a method to defragement the directory structure.\n\n\tList a directory We need to be able to list the files in a directory and the contents of the directory entry for each file in the list.\n\nRename a file Because the name of a file represents its contents to its users, we must be able to change the name when the contents or use of the file changes. Renaming a file may also allow its position within the directory structure to be changed.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 11430,
      "chunk_id": 15,
      "chunk_size": 974
    }
  },
  {
    "page_content": "Traverse the file system We may wish to access every directory and every file within a directory structure. For reliability, it is a good idea to save the contents and structure of the entire file system at regular intervals. Often, we do this by copying all files to magnetic tape other secondary storage or across a network to another system or the cloud. This technique provides a backup copy in case of system failure. In addition, if a file is no longer in use the file can be copied the backup target and the disk space of that file released for reuse by another file.\n\n11 | P a g e\n\n\n\nSingle level directory",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 12406,
      "chunk_id": 16,
      "chunk_size": 614
    }
  },
  {
    "page_content": "11 | P a g e\n\n\n\nSingle level directory\n\nThe simplest directory structure is the single-level directory. All files are contained in the same directory, which is easy to support and understand A single- level directory has significant limitations, however, when the number of files increases or when the system has more than one user. Since all files are in the same directory, they must have unique names. If two users call their data file test.txt, then the unique-name rule is violated\n\nSingle level directory\n\nTwo level directory",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 12982,
      "chunk_id": 17,
      "chunk_size": 531
    }
  },
  {
    "page_content": "Single level directory\n\nTwo level directory\n\nAs we have seen a single level directory often leads to confusion of file names among different users. But In a two-level directory structure each user has a separate User File Directory (UFD), and all UFDs are listed in a Master File Directory (MFD). This structure helps prevent filename conflicts between users but limits collaboration, as it isolates user files. To allow access to another user's file, a user must know the full path name (e.g., /user b/test.txt), combining both the username and filename.\n\nDifferent operating systems use different file naming conventions. For example, Windows uses volume letters (C:\\user b\\test.txt), while UNIX/Linux uses hierarchical  paths  (/u/pgalvin/test).  Some  systems  (like  OpenVMS)  include volume, directory, and version information in file names.\n\n12 | P a g e",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 13470,
      "chunk_id": 18,
      "chunk_size": 861
    }
  },
  {
    "page_content": "12 | P a g e\n\n\n\nFor system files (e.g., loaders or compilers), storing copies in every UFD is inefficient. Instead, a special directory stores these files, and the OS searches user directories first, then this system directory, based on a search path. The search path can be customized, allowing flexible file and command location resolution, commonly seen in UNIX and Windows systems.\n\nTwo level directory structure\n\nTree structured directories\n\nA tree-structured directory extends the two-level directory into a hierarchy of arbitrary depth, allowing users to create subdirectories to organize files logically. The structure starts with a root directory, and each file has a unique path name—either  absolute  (starting  from  root)  or  relative  (from  the  current directory).\n\nEach process typically has a current directory, set at login and inherited by subprocesses. Users can change this directory to access different files more easily.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 14319,
      "chunk_id": 19,
      "chunk_size": 945
    }
  },
  {
    "page_content": "Each process typically has a current directory, set at login and inherited by subprocesses. Users can change this directory to access different files more easily.\n\nDirectories  are  special  files  with  entries  marked  as  either  files  or subdirectories, managed  using  system  calls.  This  model  provides  flexibility, allowing logical grouping of files (e.g., separating source code and binaries).\n\nDeleting directories can follow two policies:\n\n13 | P a g e\n\n\n\nOnly allow deletion if empty, requiring manual file removal.\n\nRecursive deletion, as in UNIX's rm -r, which removes all contents but risks accidental data loss.\n\nUsers can access other users' files by specifying full path names, supporting both file organization and file sharing.\n\nAcyclic graph directories\n\nAn acyclic graph directory structure is an extension of the tree structure that allows file and directory sharing across multiple locations in the file system without duplication.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 15102,
      "chunk_id": 20,
      "chunk_size": 959
    }
  },
  {
    "page_content": "An acyclic graph directory structure is an extension of the tree structure that allows file and directory sharing across multiple locations in the file system without duplication.\n\nPurpose: Enables multiple users or directories to share the same file or \tsubdirectory, avoiding unnecessary duplication and ensuring changes are \treflected everywhere.\n\nStructure:\n\nA tree prohibits sharing.\n\nAn acyclic graph (no cycles) allows files/subdirectories to exist in multiple directories.\n\n14 | P a g e\n\n\n\nImplementation Methods:\n\nLinks (symbolic or hard) point to the actual file or directory.\n\nSymbolic links (soft): Store the path to the original file; may break if the target is deleted.\n\nHard links: Share the same inode and use a reference count to manage deletion.\n\nDuplicate entries (not recommended): Cause consistency issues when a file is modified.\n\nChallenges:\n\nMultiple path names to the same file (aliasing problem).\n\nTraversal issues during backups or system scans.\n\nDeletion complications:",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 15882,
      "chunk_id": 21,
      "chunk_size": 997
    }
  },
  {
    "page_content": "Challenges:\n\nMultiple path names to the same file (aliasing problem).\n\nTraversal issues during backups or system scans.\n\nDeletion complications:\n\nIf one user deletes a file, others may be left with dangling pointers.\n\nReference counting is used (as in UNIX) to delete a file only when all references are removed.\n\nDesign Considerations:\n\nSome\tsystems\t(for\tsimplicity\tand\tsafety)\tdo\tnot\tallow\tshared directories or links.\n\nProper management of links and deletion policies is crucial to maintain file system integrity.\n\nAn acyclic graph directory offers flexibility for sharing but adds complexity in managing references, updates, and deletions. Systems like UNIX manage this using reference counts and links while avoiding cycles to maintain structure.\n\n15 | P a g e\n\n\n\nAcyclic-graph directory structure\n\nGeneral graph directory",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 16735,
      "chunk_id": 22,
      "chunk_size": 827
    }
  },
  {
    "page_content": "15 | P a g e\n\n\n\nAcyclic-graph directory structure\n\nGeneral graph directory\n\nAn acyclic graph directory structure is designed to allow file and directory sharing while avoiding cycles to maintain simplicity and performance. However, introducing links can unintentionally create cycles, which cause serious issues.\n\nAcyclic vs. Cyclic Structure:\n\nA tree structure is naturally acyclic.\n\nAdding links can turn it into a graph, and if not managed carefully, cycles can form.\n\nProblems Caused by Cycles:\n\nInfinite loops during file searches or traversal due to re-entering the same directories.\n\nIncorrect deletion handling because files in a cycle might still show non- zero reference counts even if they're no longer accessible.\n\n16 | P a g e\n\n\n\nGarbage Collection Requirement:\n\nIf cycles exist, reference counts alone are unreliable.\n\nGarbage collection (mark-and-sweep) is needed to identify and delete unreachable files.\n\nHowever, garbage collection is slow and rarely used in disk-based systems.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 17488,
      "chunk_id": 23,
      "chunk_size": 996
    }
  },
  {
    "page_content": "Garbage collection (mark-and-sweep) is needed to identify and delete unreachable files.\n\nHowever, garbage collection is slow and rarely used in disk-based systems.\n\nCycle Prevention Strategies:\n\nUse cycle detection algorithms (costly in disk-based graphs).\n\nA practical approach is to ignore links during traversal, which avoids cycles and overhead.\n\nTo keep directory management efficient and safe, acyclic structures are preferred.  Allowing  cycles  introduces  complexity,  risks  infinite  loops,  and necessitates expensive garbage collection. Thus, systems must carefully prevent cycles when implementing file sharing via links.\n\nGeneral graph directory\n\n17 | P a g e\n\n\n\nProtection",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 18321,
      "chunk_id": 24,
      "chunk_size": 688
    }
  },
  {
    "page_content": "General graph directory\n\n17 | P a g e\n\n\n\nProtection\n\nWhen information is stored in a computer system, we want to keep it safe from physical damage (the issue of reliability) and improper access (the issue of protection).  Reliability  is  generally  provided  by  duplicate  copies  of files.Manycomput ers have systems programs that automatically (or through computer-operator intervention) copy disk files to tape at regular intervals (once per day or week or month) to maintain a copy should a file system be accidentally destroyed. File systems can be damaged by hardware problems (such as errors in reading or writing), power surgesor failures, head crashes, dirt, temperature extremes, and vandalism. Files may be deleted accidentally. Bugs in the file-system soft ware can also cause file contents to be lost.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 18958,
      "chunk_id": 25,
      "chunk_size": 816
    }
  },
  {
    "page_content": "Protection can be provided in many ways. For a laptop system running a modern operating system, we might provide protection by requiring a user nameandpasswordauthentication to access it, encrypting the secondary stor age so even someone opening the laptop and removing the drive would have a difficult time accessing its data, and firewalling network access so that when it is in use it is difficult to break in via its network connection. In multiuser system, even valid access of the system needs more advanced mechanisms to allow only valid access of the data.\n\nTypes of access",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 19776,
      "chunk_id": 26,
      "chunk_size": 581
    }
  },
  {
    "page_content": "Types of access\n\nThe need to protect files is a direct result of the ability to access files. Systems that do not permit access to the files of other users do not need protection. Thus, wecould providecomplete protection by prohibiting access. Alternatively, we could provide free access with no protection. Both approaches are too extreme for general use. What is needed is controlled access. Protection mechanisms provide controlled access by limiting the types of f ile access that can be made. Access is permitted or denied depending on several factors, one of which is the type of access requested. Several different types of operations may be controlled:\n\n18 | P a g e\n\n\n\nRead Read from the file.\n\nWrite Write or rewrite the file.\n\nExecute Load the file into memory and execute it.\n\nAppend Write newinformation at the end of the file.\n\nDelete Delete the file and free its space for possible reuse.\n\nList List the name and attributes of the file.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 20342,
      "chunk_id": 27,
      "chunk_size": 951
    }
  },
  {
    "page_content": "Append Write newinformation at the end of the file.\n\nDelete Delete the file and free its space for possible reuse.\n\nList List the name and attributes of the file.\n\nAttribute change Changing the attributes of the file.\n\nAccess control\n\nThe main idea is that file and directory access in operating systems is controlled based on user identity, using Access Control Lists (ACLs) and simplified user classifications (Owner, Group, Other) to manage permissions efficiently.\n\nAccess Control Lists (ACLs):\n\nEach file/directory can have an ACL specifying which users have which types of access (read, write, execute).\n\nOffers fine-grained control but can be long and hard to manage.\n\nSimplified Access Scheme:\n\nMost systems simplify by using three user classes:\n\nOwner: The file creator.\n\nGroup: A set of users with shared access.\n\nOther: All remaining users.\n\nEach class has read (r), write (w), and execute (x) permissions.\n\nCombining ACLs with User Classes:",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 21131,
      "chunk_id": 28,
      "chunk_size": 952
    }
  },
  {
    "page_content": "Owner: The file creator.\n\nGroup: A set of users with shared access.\n\nOther: All remaining users.\n\nEach class has read (r), write (w), and execute (x) permissions.\n\nCombining ACLs with User Classes:\n\nModern systems like UNIX and Solaris use the owner/group/other model by default, with ACLs added only when finer control is needed.\n\nExample: A project team can be a group, while temporary access for an outsider can be managed via ACLs.\n\n19 | P a g e\n\n\n\nImplementation Details:\n\nUNIX: Uses 9 permission bits (rwx for each class), with optional ACLs indicated by a “+” sign in listings.\n\nSolaris: Uses commands like setfacl and getfacl.\n\nWindows: Uses a GUI to manage ACLs and permissions.\n\nPermission Conflicts:\n\nWhen  ACLs  and  standard  group  permissions  conflict,  ACLs  take precedence, as they provide more specific rules.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 21886,
      "chunk_id": 29,
      "chunk_size": 829
    }
  },
  {
    "page_content": "Windows: Uses a GUI to manage ACLs and permissions.\n\nPermission Conflicts:\n\nWhen  ACLs  and  standard  group  permissions  conflict,  ACLs  take precedence, as they provide more specific rules.\n\nACLs provide flexible and detailed control over file access, while user classifications (owner, group, other) simplify standard permission settings. Most systems combine both approaches for efficiency and fine-tuned security, with ACLs overriding default permissions when conflicts arise.\n\nOther protection approaches",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 22522,
      "chunk_id": 30,
      "chunk_size": 512
    }
  },
  {
    "page_content": "Another approach to the protection problem is to associate a password with each file. Just as access to the computer system is often controlled by a password access to each file can be controlled in the same way. If the passwords are chosen randomly and changed often, this scheme may be effective in limiting access to a file. The use of passwords has a few disadvantages however. First, the number of passwords that a user needs to remember may become large, making the scheme impractical. Second, if only one password is used for all the files then once it is discovered all files are accessible protection is on an all-or-none basis. Some systems allow a user to associate a password with a subdirectory rather than with an individual file to address this problem. In a multilevel directory structure, we need  to  protect  not  only  individual  files  but  also  collections  of  files  in subdirectories; that is, we need to provide a mechanism for directory protection. The directory",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 23036,
      "chunk_id": 31,
      "chunk_size": 991
    }
  },
  {
    "page_content": "structure, we need  to  protect  not  only  individual  files  but  also  collections  of  files  in subdirectories; that is, we need to provide a mechanism for directory protection. The directory operations that must be protected are somewhat different from the file operations. We want to control the creation and deletion of files in a directory. In addition, we probably want to control whether a user can determine the",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 23831,
      "chunk_id": 32,
      "chunk_size": 423
    }
  },
  {
    "page_content": "20 | P a g e\n\n\n\nexistence of a file in a directory. Sometimes knowledge of the existence and name of a file is significant in itself.\n\nThus, listing the contents of a directory must be a protected operation.\n\nSimilarly, if a path name refers to a file in a directory, the user must be allowed access to both the directory and the file. In systems where files may have\n\nnumerous path names (such as acyclic and general graphs), a given user may have different access rights to a particular file, depending on the path name used.\n\n21 | P a g e\n\n\n\nMemory mapped files",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 24256,
      "chunk_id": 33,
      "chunk_size": 564
    }
  },
  {
    "page_content": "numerous path names (such as acyclic and general graphs), a given user may have different access rights to a particular file, depending on the path name used.\n\n21 | P a g e\n\n\n\nMemory mapped files\n\nThere is one other method of accessing files, and it is very commonly used. Consider a sequential read of a file on disk using the standard system calls open(), read(),andwrite().  Each  file  access  requires  a  system  call  and  disk  access. Alternatively, we can use the virtual memory techniques in to treat file I/O as routine memory accesses. This approach, known as memory mapping a file, allows a part of the virtual address space to be logically associated with the file. As we shall see, this can lead to significant performance increases.\n\nBasic mechanism",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 24625,
      "chunk_id": 34,
      "chunk_size": 766
    }
  },
  {
    "page_content": "Basic mechanism\n\nMemory-mapped files are a powerful mechanism used by modern operating systems to optimize file access and enable interprocess communication. Instead of reading and writing files through traditional system calls like read() and write(), memory mapping allows a file to be directly mapped into the virtual memory space of a process. This approach not only improves performance by eliminating the overhead of frequent system calls but also simplifies file manipulation by treating file content as if it were part of the main memory.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 25376,
      "chunk_id": 35,
      "chunk_size": 546
    }
  },
  {
    "page_content": "When a file is memory-mapped, the operating system links disk blocks to pages in virtual memory. The first time a part of the file is accessed, a page fault occurs, prompting the OS to load that portion of the file from disk into a physical memory  page.  Subsequent  accesses  are  handled  like  ordinary  memory operations. Writes to the file, however, are not immediately saved to disk. Instead, they are temporarily stored in memory and only written back to disk either when the file is closed or under memory pressure, ensuring data is not lost.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 25924,
      "chunk_id": 36,
      "chunk_size": 551
    }
  },
  {
    "page_content": "Different operating systems implement memory mapping in different ways. For instance, Solaris automatically memory-maps files, whether they are accessed through  explicit  memory-mapping  system  calls  (like  mmap())  or  through traditional file access methods. If accessed through standard system calls, Solaris maps the file to the kernel address space, while memory-mapped files are placed in the process address space. In either case, the file I/O benefits from the speed and efficiency of memory operations.\n\n22 | P a g e",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 26477,
      "chunk_id": 37,
      "chunk_size": 528
    }
  },
  {
    "page_content": "22 | P a g e\n\n\n\nAn important advantage of memory-mapped files is their ability to enable data sharing between processes. When multiple processes map the same file, they share the same physical memory pages, so changes made by one process can be instantly seen by the others. This sharing mechanism can be controlled using mutual  exclusion  methods  to  ensure  consistency  and  synchronization. Additionally, copy-on-write can be used to allow multiple processes to share read- only access while creating separate memory copies if any process attempts to modify the data.\n\nBeyond file access, memory mapping also plays a vital role in interprocess communication (IPC). Shared memory segments are often created by memory- mapping files into the address space of communicating processes. This technique provides an efficient way for processes to exchange information by reading and writing to a common memory region without the need for slower I/O operations.",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 26993,
      "chunk_id": 38,
      "chunk_size": 959
    }
  },
  {
    "page_content": "memory-mapped files streamline file access and enhance performance by reducing system call overhead and enabling direct memory manipulation. They also provide a foundation for efficient shared memory, facilitating fast and simple communication  between  processes.  By  integrating  file  I/O  and  memory management, memory mapping is a key feature in modern operating systems that supports both performance optimization and process collaboration.\n\nShared memory in the window API\n\nThe general outline for creating a region of shared memory using memory mappedfiles in the Windows API involves first creating a fil mapping for the file to be mapped and then establishing a view of the mapped file in a process’s virtual address space. A second process can then open and create a view of the mapped file in its virtual address space. The mapped file represents the shared- memory object that will enable communication to take place between the\n\nprocesses",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 27954,
      "chunk_id": 39,
      "chunk_size": 954
    }
  },
  {
    "page_content": "processes\n\nWe next illustrate these steps in more detail. In this example, a producer process first creates a shared-memory object using the memory-mapping fea\n\n23 | P a g e\n\n\n\ntures available in the Windows API. The producer then writes a message to shared memory. After that a consumer process opens a mapping to the shared memory object and reads the message written by the consumer\n\nMemory mapped files\n\nshared memory using memory mapped I/O\n\n24 | P a g e\n\n\n\nReferences\n\nOperating system concepts tenth edition by ABRAHAM SILBERSCHATZ, PETER BAER GALVIN, GREG GAGNE\n\nOperating system concepts ninth edition by ABRAHAM SILBERSCHATZ, PETER BAER GALVIN, GREG GAGNE\n\nModern operating system fourth edition by ANDREW S. TANENBAUM HERBERT BOS\n\ninternet\n\n25 | P a g e",
    "metadata": {
      "source": "/tmp/tmpnun2_hhg.pptx",
      "start_index": 28899,
      "chunk_id": 40,
      "chunk_size": 764
    }
  }
]