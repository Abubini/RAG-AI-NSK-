[
  {
    "page_content": "LangChain\nVasilios Mavroudis\nAlan Turing Institute\nvmavroudis@turing.ac.uk\nAbstract. LangChain is a rapidly emerging framework that offers a ver-\nsatile and modular approach to developing applications powered by large\nlanguage models (LLMs). By leveraging LangChain, developers can sim-\nplify complex stages of the application lifecycle—such as development,\nproductionization, and deployment—making it easier to build scalable,\nstateful, and contextually aware applications. It provides tools for han-\ndling chat models, integrating retrieval-augmented generation (RAG),\nand offering secure API interactions. With LangChain, rapid deployment\nof sophisticated LLM solutions across diverse domains becomes feasible.\nHowever, despite its strengths, LangChain’s emphasis on modularity and\nintegration introduces complexities and potential security concerns that\nwarrant critical examination. This paper provides an in-depth analysis\nof LangChain’s architecture and core components, including LangGraph,",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 0,
      "page_label": "1"
    }
  },
  {
    "page_content": "warrant critical examination. This paper provides an in-depth analysis\nof LangChain’s architecture and core components, including LangGraph,\nLangServe,andLangSmith.Weexplorehowtheframeworkfacilitatesthe\ndevelopment of LLM applications, discuss its applications across multi-\nple domains, and critically evaluate its limitations in terms of usability,\nsecurity, and scalability. By offering valuable insights into both the capa-\nbilities and challenges of LangChain, this paper serves as a key resource\nfor developers and researchers interested in leveraging LangChain for\ninnovative and secure LLM-powered applications.\nKeywords: LangChain · Large Language Models· LLM Applications·\nModular Framework\nThe emergence of large language models (LLMs) such as OpenAI’s o1 [13],\nGPT-4o [12], Google’s Gemini [14], and Meta’s LLaMA [16] has revolutionized\nthe field of natural language processing (NLP). These advanced models have un-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 0,
      "page_label": "1"
    }
  },
  {
    "page_content": "GPT-4o [12], Google’s Gemini [14], and Meta’s LLaMA [16] has revolutionized\nthe field of natural language processing (NLP). These advanced models have un-\nlocked unprecedented capabilities in understanding and generating human-like\ntext, enabling applications that range from intelligent conversational agents to\nsophisticated data analysis tools. However, harnessing the full potential of LLMs\nin real-world applications presents significant challenges. Developers must nav-\nigate complexities related to model integration, state management, scalability,\ncontextual awareness, and security.\nLangChain has rapidly gained prominence as a powerful framework designed\nto address these challenges in developing LLM-powered applications [2]. By\nproviding a modular and flexible architecture, LangChain simplifies the com-\nplexities inherent in working with LLMs, enabling developers to build scalable,",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 0,
      "page_label": "1"
    }
  },
  {
    "page_content": "2 Vasilios Mavroudis\nstateful, and contextually aware applications with ease. Its suite of compo-\nnents—including LangGraph for stateful process modeling, LangServe for scal-\nableAPIdeployment,andLangSmithformonitoringandevaluation—collectively\nform a comprehensive toolkit for leveraging LLMs effectively [3].\nLangChain facilitates the integration of LLMs into a wide array of applica-\ntions, empowering developers to create solutions that are not only functional\nbut also efficient and secure. Its support for features like chat models, retrieval-\naugmented generation (RAG) [10], and secure API interactions allows for the\nrapid deployment of sophisticated language model solutions across diverse do-\nmains such as healthcare, customer service, finance, and mental health.\nDespite its strengths, LangChain’s emphasis on flexibility through modular-\nity introduces certain complexities. Developers may encounter a steep learning",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 1,
      "page_label": "2"
    }
  },
  {
    "page_content": "Despite its strengths, LangChain’s emphasis on flexibility through modular-\nity introduces certain complexities. Developers may encounter a steep learning\ncurve when navigating its extensive components and integrations. Moreover, the\nreliance on external integrations and third-party providers necessitates a careful\nexamination of security practices to mitigate risks associated with data exposure\nand dependency vulnerabilities.\nThis paper provides a comprehensive analysis of LangChain, delving into its\narchitecture, core components, and the interplay between its modules. We ex-\nplore how LangChain facilitates the development of LLM applications by exam-\nining each component’s functionality and their synergistic contributions to the\nframework. Furthermore, we critically evaluate the limitations and criticisms of\nLangChain, focusing on the complexities introduced by its modular design and\nthe security implications of its extensive integrations.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 1,
      "page_label": "2"
    }
  },
  {
    "page_content": "LangChain, focusing on the complexities introduced by its modular design and\nthe security implications of its extensive integrations.\nBy offering valuable insights into both the capabilities and challenges of\nLangChain, this paper aims to serve as a key resource for developers and re-\nsearchers interested in LLM application development. We seek to illuminate\nthe transformative potential of LangChain in advancing NLP applications while\nproviding a nuanced understanding of its practical boundaries. Ultimately, this\nanalysis guides users in effectively harnessing LangChain to build innovative and\nsecure LLM-powered applications tailored to their specific needs.\nThe remainder of this paper is organized as follows: Section 1 delves into\nthe core architecture of LangChain, detailing its primary components and their\nfunctionalities. Section 2 examines LangSmith and its role in monitoring and\nevaluation of LLM applications. In Section 3, we explore LangGraph’s capabili-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 1,
      "page_label": "2"
    }
  },
  {
    "page_content": "functionalities. Section 2 examines LangSmith and its role in monitoring and\nevaluation of LLM applications. In Section 3, we explore LangGraph’s capabili-\nties in stateful process modeling. Section 4 discusses LangServe for scalable API\ndeployment of LangChain applications. Finally, section 5 addresses the limita-\ntions and criticisms of LangChain, particularly focusing on the complexities and\nsecurity concerns associated with its modular design and external integrations.\n1 Architecture\nLangChain is built with a modular architecture, designed to simplify the life-\ncycle of applications powered by large language models (LLMs), from initial\ndevelopment through to deployment and monitoring [3]. This modularity al-\nlows developers to configure, extend, and deploy applications tailored to specific",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 1,
      "page_label": "2"
    }
  },
  {
    "page_content": "LangChain 3\nneeds, providing a flexible foundation for building scalable, secure, and multi-\nfunctional applications. Figure 1 illustrates a fundamental LangChain pipeline.\nIn this architecture, diverse data sources—including documents, text, and im-\nages—are embedded and stored within a vector store. Upon receiving a user’s\nquery, the system retrieves the most relevant information from the vector store.\nThis retrieved context is then provided to the large language model (LLM),\nenhancing its ability to generate accurate and factually grounded responses.\nFig. 1.LangChain pipeline architecture showcasing the retrieval-augmented genera-\ntion process. Documents in various formats (e.g., PDF, text, images) are preloaded\nand embedded into a vector store. When a user submits a query, the system retrieves\nthe top-k most relevant documents based on vector similarity. These documents are\ncombined with the query to provide contextual information to the language model",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 2,
      "page_label": "3"
    }
  },
  {
    "page_content": "the top-k most relevant documents based on vector similarity. These documents are\ncombined with the query to provide contextual information to the language model\n(LLM), which then generates an accurate and contextually enriched answer. This ar-\nchitecture enhances the model’s ability to produce factually grounded responses by\nincorporating relevant knowledge from the vector store.\nThe rest of this section provides an overview of LangChain’s primary com-\nponents, followed by a brief introduction to its advanced modules–LangSmith,\nLangGraph and LangServe–which are further discussed in Sections 2, 3, and 4\nrespectively:\nLLM Interface: Provides APIs for connecting and querying various large lan-\nguage models, such as OpenAI’s GPT [1], Google’s Gemini [14], and Llama [16],\nto facilitate seamless application integration.\nPromptTemplates:Structuredtemplatesthatstandardizeandformatqueries,\nensuring consistency and precision in interactions with AI models. These tem-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 2,
      "page_label": "3"
    }
  },
  {
    "page_content": "to facilitate seamless application integration.\nPromptTemplates:Structuredtemplatesthatstandardizeandformatqueries,\nensuring consistency and precision in interactions with AI models. These tem-\nplates help guide the model towards producing reliable and relevant outputs.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 2,
      "page_label": "3"
    }
  },
  {
    "page_content": "4 Vasilios Mavroudis\nMemory: Enables applications to retain information from past interactions,\nsupporting both basic and advanced memory structures. This component is crit-\nical for maintaining context across sessions and delivering contextually aware\nresponses.\nIndexes: Serve as structured databases that organize and store information,\nallowing for efficient data retrieval when processing language queries.\nRetrievers: Designed to work alongside indexes, retrievers fetch relevant data\nbased on query inputs, ensuring that the generated responses are well-informed\nand accurate.\nVector Store: Manages the embedding of words or phrases as numerical vec-\ntors, a core step in capturing semantic meaning and supporting tasks involving\nlanguage understanding and similarity searches.\nOutput Parsers: Components that refine and structure the generated language\noutputs for specific tasks, ensuring usability and relevance for the application’s\ngoals.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 3,
      "page_label": "4"
    }
  },
  {
    "page_content": "Output Parsers: Components that refine and structure the generated language\noutputs for specific tasks, ensuring usability and relevance for the application’s\ngoals.\nAgents: Custom chains that prompt the language model to identify and execute\nthe most effective sequence of actions for a given query, enabling adaptive and\ndynamic decision-making.\nCallbacks:Functionsthatlog,monitor,andstreamspecificeventswithinLangChain\nworkflows, simplifying tracking and debugging processes.\n1.1 Chat Models and Message Handling\nLangChain supports chat models that manage complex, multi-turn conversa-\ntions. These models use structured message sequences, allowing developers to\ncontrol conversation flow and maintain state over time. The structured message\nhandling system enables robust interactions with users by storing and retrieving\nconversation history as needed [6]. Their key features include:\n– Multi-turn Interactions: LangChain maintains state across conversation",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 3,
      "page_label": "4"
    }
  },
  {
    "page_content": "conversation history as needed [6]. Their key features include:\n– Multi-turn Interactions: LangChain maintains state across conversation\nturns, making it suitable for prolonged, context-dependent conversations.\n– Structured Output: Supports structured responses like JSON, allowing\neasy integration with downstream applications.\n– Conversation Memory: Maintains continuity by storing conversation his-\ntory, ideal for applications requiring persistent context, such as customer\nsupport [4].\n1.2 Retrieval-Augmented Generation (RAG)\nLangChain supports Retrieval-Augmented Generation (RAG), which integrates\nlanguage models with external knowledge bases to enhance response accuracy",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 3,
      "page_label": "4"
    }
  },
  {
    "page_content": "LangChain 5\nand relevance. RAG allows models to access up-to-date information, extending\ntheir capabilities beyond their training data. LangChain’s RAG implementation\nuses:\n– Document Loaders and Text Splitters: Preprocess documents for in-\ndexing and efficient retrieval [6].\n– Embedding Models and Vector Stores: Enable similarity-based re-\ntrieval by embedding documents into vector spaces. LangChain integrates\nwithvectorstoragesolutionslikeChromaandMilvusforoptimizedsearches[3].\n– Retrievers and RAG Chains: Retrieve and merge external data with\nmodel responses, enhancing applications such as question answering systems\nand recommendation engines [4].\n1.3 Security and Permissions Management\nSecurity is a critical focus in LangChain’s design, particularly given the potential\naccess to external data sources. LangChain addresses these security challenges\nthrough best practices and internal controls [3]:\n– Granular Permissions: Enforces the principle of least privilege by allowing",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 4,
      "page_label": "5"
    }
  },
  {
    "page_content": "through best practices and internal controls [3]:\n– Granular Permissions: Enforces the principle of least privilege by allowing\ndevelopers to specify limited permissions, minimizing the risk of unautho-\nrized actions.\n– Sandboxing and Defense in Depth: Utilizes sandboxed environments\nand layered security to protect sensitive data and limit exposure to vulner-\nabilities [3].\n– Auditability and Monitoring: LangSmith (see Section 2) provides de-\ntailed logging and monitoring capabilities, enabling developers to track ap-\nplication usage and detect anomalies in real time.\n1.4 Integrations and Extensibility\nLangChain’s architecture supports a wide range of third-party integrations, al-\nlowing for custom component development and additional functionality, such as\nmulti-modal data processing and AI tool integration [3]:\n– IntegrationPackages:LangChainprovidesdedicatedpackages(e.g.,langchain-\nopenai, langchain-aws) that simplify connections to external platforms, tai-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 4,
      "page_label": "5"
    }
  },
  {
    "page_content": "– IntegrationPackages:LangChainprovidesdedicatedpackages(e.g.,langchain-\nopenai, langchain-aws) that simplify connections to external platforms, tai-\nloring applications to specific needs.\n– Support for Multi-modal Data: Supports image, text, and audio inputs,\nallowing for applications like chatbots capable of interpreting diverse data\ntypes.\n– CustomComponentDevelopment :Developerscanbuildcustomplugins\nor extend LangChain components, ensuring flexibility and adaptability for\na wide range of application requirements.\nLangChain’s modular and flexible architecture equips developers with a com-\nprehensive toolkit for building, deploying, and monitoring LLM applications. Its\nadvanced components—LangGraph, LangServe, and LangSmith—enable sophis-\nticated functionality for scalable, interactive, and robust applications, meeting\nthe demands of modern AI use cases.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 4,
      "page_label": "5"
    }
  },
  {
    "page_content": "6 Vasilios Mavroudis\n1.5 Advanced Components\nBeyond these core elements, LangChain offers advanced modules that support\ncomplex workflows, API deployments, and performance monitoring. These com-\nponents are elaborated in the following sections:\n– LangGraph for Stateful Process Modeling: Explored in Section 3,\nLangGraph enables developers to structure applications with nodes and\nedges, allowing for complex branching and multi-agent workflows.\n– LangServe for API Deployment: Detailed in Section 4, LangServe facil-\nitates the deployment of LangChain applications as REST APIs, supporting\nscalability in production [5].\n– LangSmith for Monitoring and Evaluation: Discussed in Section 2,\nLangSmith offers tools for real-time performance monitoring, error tracking,\nand version control to optimize applications iteratively [4].\n2 LangSmith\nLangSmith is a developer platform tailored to streamline the deployment, mon-\nitoring, and evaluation of large language model (LLM) applications, provid-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 5,
      "page_label": "6"
    }
  },
  {
    "page_content": "2 LangSmith\nLangSmith is a developer platform tailored to streamline the deployment, mon-\nitoring, and evaluation of large language model (LLM) applications, provid-\ning essential tools for building production-grade systems. Integrated with the\nLangChain ecosystem, it enables users to trace, evaluate, and refine applications,\nenhancing precision in complex environments. The platform addresses key chal-\nlenges in observability, testing, and optimization, allowing developers to monitor\nperformance, troubleshoot issues, and maintain high standards over time [9].\n2.1 Tracing\nTracing is a central feature of LangSmith, providing detailed visibility into how\napplications interact with LLMs and external data sources. For developers using\nLangChain, LangSmith offers tracing without the need for direct SDK inte-\ngration, simplifying the monitoring process. Tracing involves capturing inputs,\noutputs, and critical metadata from each interaction, allowing developers to ob-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 5,
      "page_label": "6"
    }
  },
  {
    "page_content": "gration, simplifying the monitoring process. Tracing involves capturing inputs,\noutputs, and critical metadata from each interaction, allowing developers to ob-\nserve and analyze component behavior in real time. This capability is especially\nuseful for debugging and identifying bottlenecks within complex workflows.\nLangSmith supports multiple ways to log traces, including languages like\nPython and TypeScript. Each trace logs every call made to an LLM, along with\ninput parameters, function annotations, and generated outputs, making it easier\nto identify where adjustments may be necessary. By using traceable wrappers\nand decorators, developers can annotate functions or data pipelines, enabling\nautomatic trace logging with minimal code alterations [9].\n2.2 Performance Testing\nLangSmith’s evaluation tools enable developers to test and validate applica-\ntions under real-world conditions. Evaluations require a defined dataset of test",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 5,
      "page_label": "6"
    }
  },
  {
    "page_content": "LangChain 7\ncases, including inputs and expected outputs. Using these datasets, developers\ncan conduct performance tests and assess how well their models meet expected\noutcomes—an essential step for applications where accuracy and reliability are\ncrucial. LangSmith supports custom evaluators, allowing developers to specify\nscoring functions based on specific needs. For instance, an evaluator may mea-\nsure the exact match between outputs and expected answers, or use metrics\nlike cosine similarity for open-ended tasks. By supporting both built-in and cus-\ntom evaluators, LangSmith provides flexibility in performance measurement for\ndeterministic outputs or nuanced language generation tasks [9].\n2.3 Dataset Management\nDatasets are foundational to LangSmith’s evaluation system. Organizing test\ncases into structured datasets enables methodical testing and validation. De-\nvelopers can create datasets manually or import them from existing sources,",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 6,
      "page_label": "7"
    }
  },
  {
    "page_content": "cases into structured datasets enables methodical testing and validation. De-\nvelopers can create datasets manually or import them from existing sources,\nallowing diverse testing scenarios that reflect real-world use cases. Datasets can\ncontain structured or unstructured data evaluations, accommodating a variety of\ntesting needs. LangSmith’s dataset version control allows developers to maintain\nmultiple dataset versions as applications evolve. This feature is critical for ensur-\ning consistency in evaluation, especially as application logic changes or models\nare retrained, providing a robust foundation for testing and validation [9].\n2.4 LangSmith Workflow\nLangSmith integrates tracing, evaluation, and dataset management into a cohe-\nsive framework, enabling developers to progress from debugging to optimization\nin a structured manner. A typical LangSmith workflow includes the following\nstages:\n– Trace Logging: Developers activate tracing on application functions, pro-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 6,
      "page_label": "7"
    }
  },
  {
    "page_content": "in a structured manner. A typical LangSmith workflow includes the following\nstages:\n– Trace Logging: Developers activate tracing on application functions, pro-\nviding insights into model-component interactions.\n– Dataset Creation and Evaluation: Developers create datasets represent-\ning different scenarios to conduct comprehensive testing.\n– Evaluation and Iterative Optimization: Evaluation results indicate per-\nformance areas for refinement, guiding iterative application improvements.\n– Version Control and Historical Tracking: LangSmith logs all interac-\ntions, dataset versions, and evaluation scores, allowing developers to assess\nimprovements over time.\n2.5 Integration with LangChain and LangServe\nLangSmith integrates seamlessly with LangChain and LangServe (Section 4) to\nenhancetheend-to-endLLMapplicationdevelopmentexperience.ForLangChain\nusers, LangSmith can automatically log traces and integrate with existing work-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 6,
      "page_label": "7"
    }
  },
  {
    "page_content": "enhancetheend-to-endLLMapplicationdevelopmentexperience.ForLangChain\nusers, LangSmith can automatically log traces and integrate with existing work-\nflows. Combined with LangServe, LangSmith provides robust observability for\nAPI deployments, monitoring real-time usage patterns, tracking request laten-\ncies, and identifying bottlenecks.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 6,
      "page_label": "7"
    }
  },
  {
    "page_content": "8 Vasilios Mavroudis\n3 LangGraph\nLangGraph is a low-level framework for building stateful, multi-actor appli-\ncations with large language models (LLMs). It provides developers with fine-\ngrained control over application flows, incorporating cycles, branching, and per-\nsistence to support complex agent workflows. Inspired by frameworks such as\nPregel [11] and Apache Beam [15], LangGraph enables advanced human-in-the-\nloop applications and persistent state management, allowing for more reliable\nand adaptable LLM-powered systems [7].\n3.1 Core Features of LangGraph\nCycles and Branching LangGraph distinguishes itself by supporting cycles\nand branching in application workflows. This feature is particularly beneficial\nfor agentic architectures that require iterative or conditional logic. By enabling\ncycles within workflows, LangGraph provides a flexible structure that allows\nnodes to execute repeatedly until a specified condition is met. This contrasts",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 7,
      "page_label": "8"
    }
  },
  {
    "page_content": "cycles within workflows, LangGraph provides a flexible structure that allows\nnodes to execute repeatedly until a specified condition is met. This contrasts\nwith typical directed acyclic graph (DAG)-based architectures, which are limited\nto single-pass execution without feedback loops [7].\nPersistence and State ManagementOne of LangGraph’s key innovations is\nits built-in support for persistence, which enablesstate to be saved and accessed\nthroughout the application’s lifecycle. This persistent state management is cru-\ncial for applications that require continuity across sessions, such as customer ser-\nvice agents or educational tools that need to recall previous interactions. Lang-\nGraph’s persistence feature also facilitates advanced human-in-the-loop work-\nflows, allowing agents to pause, receive human input, and resume operations\nseamlessly.\nLangGraph utilizes a stateful execution model where each node in the graph",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 7,
      "page_label": "8"
    }
  },
  {
    "page_content": "flows, allowing agents to pause, receive human input, and resume operations\nseamlessly.\nLangGraph utilizes a stateful execution model where each node in the graph\nupdates the application state as it processes input. For instance, in a multi-turn\nconversation, the graph maintains a memory of all previous messages, which can\nbe accessed by subsequent nodes to ensure coherent responses. This persistent\nstate can also be saved externally using the LangGraph Platform [8], ensuring\nrobust memory management across long-running sessions [7].\nHuman-in-the-Loop and Streaming Support LangGraph offers built-in\nsupport for human-in-the-loop interactions, which is essential for applications\nthat require manual intervention or approval at certain stages. For example, a\nhuman operator can review an agent’s planned actions and approve, reject, or\nmodify them before the agent proceeds. This level of control makes LangGraph\nsuitable for high-stakes domains like healthcare or legal advice, where accuracy",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 7,
      "page_label": "8"
    }
  },
  {
    "page_content": "modify them before the agent proceeds. This level of control makes LangGraph\nsuitable for high-stakes domains like healthcare or legal advice, where accuracy\nand oversight are critical.\nAdditionally, LangGraph supports streaming outputs from each node as they\nare produced. This capability is especially useful for applications like chatbots",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 7,
      "page_label": "8"
    }
  },
  {
    "page_content": "LangChain 9\nor real-time monitoring systems, where immediate feedback improves user expe-\nrience. Streaming can be implemented within any node in the graph, enabling\nreal-time updates as actions are processed [7].\n3.2 LangGraph Platform\nThe LangGraph Platform [8] is an infrastructure solution that extends the\nopen-source LangGraph framework for production deployments. It includes com-\nponents like LangGraph Server (for API access), LangGraph SDKs (client li-\nbraries), and LangGraph CLI (a command-line interface for deployment manage-\nment). The platform is designed to handle complex agent workflows, supporting\nlong-running agents, background processing, and task queuing to ensure reliable\nperformance even under heavy loads. The LangGraph Platform also includes\nfeatures such as:\n– Background Execution: Allows agents to run asynchronously, handling\nuser requests in parallel without blocking other tasks.\n– Support for Long-Running Agents: Provides infrastructure for agents",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 8,
      "page_label": "9"
    }
  },
  {
    "page_content": "– Background Execution: Allows agents to run asynchronously, handling\nuser requests in parallel without blocking other tasks.\n– Support for Long-Running Agents: Provides infrastructure for agents\nthat need to operate over extended periods, managing resource allocation\nand monitoring agent health.\n– Burst Handling and Task Queues: Uses queues to manage sudden in-\ncreases in requests, ensuring that high-priority tasks are processed efficiently.\n3.3 LangGraph Workflow\nA typical LangGraph workflow begins by defining the state schema and nodes\nrequired for the application. Each node represents an independent function, such\nas calling an LLM, invoking a tool, or accessing external data. The developer sets\nan entry point for graph execution and defines the transitions (edges) between\nnodes, which can be conditional or sequential based on application requirements.\n– Defining Nodes and State: Developers initialize nodes, such as an LLM",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 8,
      "page_label": "9"
    }
  },
  {
    "page_content": "nodes, which can be conditional or sequential based on application requirements.\n– Defining Nodes and State: Developers initialize nodes, such as an LLM\nnode for responses or a tool node for external API calls, and specify the state\nschema to manage conversation context.\n– Setting Entry Points and Edges: Nodes are connected by edges, with\nconditions determining the flow based on the application’s state.\n– CompilingandExecutingtheGraph :Oncenodesandedgesaredefined,\nthe graph is compiled into a runnable format, enabling calls to functions such\nas invoke() for execution andstream() for real-time updates.\nLangGraph’s workflow design allows applications to cycle between nodes\nbased on input conditions and dynamically update state, enabling applications\nthat require complex interaction patterns.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 8,
      "page_label": "9"
    }
  },
  {
    "page_content": "10 Vasilios Mavroudis\n3.4 Integration with LangChain and LangSmith\nLangGraph integrates seamlessly with LangChain and LangSmith, although\nit operates independently if desired. For users within the LangChain ecosys-\ntem, LangGraph can utilize LangSmith’s tracing capabilities to monitor each\nnode’s performance and capture detailed logs of agent interactions. Addition-\nally, LangChain tools and APIs can be incorporated as graph nodes, expanding\nLangGraph’s functionality with LangChain’s extensive library of tools and con-\nnectors [7].\n4 LangServe\nLangServe [5] is an integral component of the LangChain ecosystem, specifically\ndesignedtofacilitatethedeploymentoflargelanguagemodel(LLM)applications\nas scalable REST APIs. With LangServe, developers can create production-\ngrade APIs that allow external systems and users to interact with LangChain\napplications. It enables LLM-powered applications to be served in real-time with\nrobust support for load balancing, monitoring, and scalability.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 9,
      "page_label": "10"
    }
  },
  {
    "page_content": "applications. It enables LLM-powered applications to be served in real-time with\nrobust support for load balancing, monitoring, and scalability.\n4.1 Core Features of LangServe\nAPI Deployment and Management LangServe simplifies the process of\nturning LangChain applications into APIs, making LLM models accessible for\nvarious services and client applications. With LangServe, any LangChain work-\nflow can be packaged and exposed via RESTful endpoints, enabling interactions\nwith language models, data retrieval, and external tool integration. The API-\ncentric design allows LangServe to support diverse use cases, from chatbots and\nrecommendation systems to complex multi-agent interactions. It provides several\ntools for managing API endpoints, such as configurable routing, request han-\ndling, and response formatting, which make it easy to customize each endpoint\nbased on application requirements. This flexibility allows developers to design",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 9,
      "page_label": "10"
    }
  },
  {
    "page_content": "dling, and response formatting, which make it easy to customize each endpoint\nbased on application requirements. This flexibility allows developers to design\nAPIs with specific functionalities, making LangServe suitable for applications of\nvarying complexity [5].\nScalability and Load BalancingLangServe includes built-in support for scal-\nability, making it ideal for applications that experience high traffic volumes. It\ncan handle multiple API requests simultaneously, ensuring consistent perfor-\nmance by balancing the load across instances. This feature is critical for pro-\nduction environments where maintaining low response times under heavy loads\nis essential. To further enhance scalability, LangServe provides tools for setting\nup auto-scaling, which dynamically adjusts the number of instances based on\ndemand. This allows applications to handle traffic spikes without degradation\nin performance, making LangServe suitable for real-world deployments with un-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 9,
      "page_label": "10"
    }
  },
  {
    "page_content": "demand. This allows applications to handle traffic spikes without degradation\nin performance, making LangServe suitable for real-world deployments with un-\npredictable usage patterns [5].",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 9,
      "page_label": "10"
    }
  },
  {
    "page_content": "LangChain 11\nLatency and Error ManagementLangServe is designed to minimize latency,\nensuring quick responses for each API request. It employs efficient request queu-\ning and processing mechanisms to reduce waiting times. Additionally, LangServe\nincludes error handling and retry logic, which helps maintain reliability by man-\naging transient failures and minimizing downtime. This focus on latency and\nerror resilience makes LangServe suitable for mission-critical applications that\nrequire high availability. For instance, LangServe can automatically retry failed\nrequests and log errors for further investigation, allowing developers to identify\nissues promptly and maintain a stable API response rate [5].\n4.2 LangServe Workflow\nThe LangServe deployment workflow is straightforward, enabling developers to\ngo from a LangChain application to a deployed API in a few steps. Here’s an\noutline of a typical LangServe workflow:",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 10,
      "page_label": "11"
    }
  },
  {
    "page_content": "The LangServe deployment workflow is straightforward, enabling developers to\ngo from a LangChain application to a deployed API in a few steps. Here’s an\noutline of a typical LangServe workflow:\n1. Defining Endpoints: Developers define endpoints based on application re-\nquirements, specifying which functions or models are exposed via API routes.\nEach endpoint can have customized parameters, allowing for flexibility in\nhow the API interacts with different components.\n2. ConfiguringRequestHandlingandRouting :LangServeallowsforfine-\ngrained control over how requests are processed. Developers can set up rout-\ning rules, parameter validation, and request parsing to tailor the API expe-\nrience.\n3. Setting Up Load Balancing and Scaling: For applications with high\ntraffic, LangServe’s load balancing can be configured to distribute requests\nacross multiple instances, ensuring consistent response times. Auto-scaling\ncan also be set up to dynamically adjust resources based on demand.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 10,
      "page_label": "11"
    }
  },
  {
    "page_content": "across multiple instances, ensuring consistent response times. Auto-scaling\ncan also be set up to dynamically adjust resources based on demand.\n4. Monitoring and Error Tracking: LangServe integrates with monitoring\ntools, including LangSmith, to provide real-time insights into API perfor-\nmance, usage metrics, and error rates. This monitoring helps developers\nmaintain optimal performance and quickly resolve issues as they arise.\nLangServe’s streamlined workflow ensures that developers can deploy robust\nAPIs with minimal overhead, making it a practical choice for scaling LLM ap-\nplications in production environments.\n4.3 Integration with LangSmith and LangChain\nLangServe integrates seamlessly with LangSmith, which offers observability fea-\ntures like tracing, logging, and performance monitoring. Through LangSmith,\nLangServe users can track metrics such as request frequency, latency, and er-\nror rates. This integration provides a comprehensive view of API performance,",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 10,
      "page_label": "11"
    }
  },
  {
    "page_content": "LangServe users can track metrics such as request frequency, latency, and er-\nror rates. This integration provides a comprehensive view of API performance,\nenabling developers to optimize applications based on real-time data.\nAdditionally, LangServe’s integration with LangChain allows developers to\nleverage LangChain’s extensive library of tools, models, and connectors as part",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 10,
      "page_label": "11"
    }
  },
  {
    "page_content": "12 Vasilios Mavroudis\nof the API. LangChain workflows, tools, and chains can be directly exposed\nvia LangServe endpoints, providing flexible API interactions and enhancing the\nfunctionality of LLM applications [5].\n5 Limitations and Criticisms\nLangChain provides a versatile framework for the development of applications\npowered by large language models (LLMs). However, several limitations warrant\nattention, especially in the domains of complexity and security.\n5.1 Complexity\nLangChain’s modular architecture, while designed to simplify LLM-based ap-\nplication development, can paradoxically increase complexity. Effective use of\nLangChain often requires a nuanced understanding of its distinct components,\nsuch as LangGraph and LangSmith, as well as familiarity with its API ecosys-\ntem. Consequently, developers may face a steep learning curve, particularly those\naiming for rapid prototyping or deployment. The need for comprehensive knowl-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 11,
      "page_label": "12"
    }
  },
  {
    "page_content": "tem. Consequently, developers may face a steep learning curve, particularly those\naiming for rapid prototyping or deployment. The need for comprehensive knowl-\nedge of each module may present a barrier to new users, complicating onboarding\nand initial implementation phases.\n5.2 Security Concerns\nGiven LangChain’s modular design and extensive reliance on external integra-\ntions, security presents a notable challenge. Although LangChain incorporates a\nrange of security measures, including fine-grained permission control and sand-\nboxing, the complexity of securing LLM-based applications remains high, espe-\ncially for applications managing sensitive data. Below, we outline several critical\nsecurity risks associated with LangChain and explore strategies for risk mitiga-\ntion.\nRisksAssociatedwithExternalProviders Toenhancefunctionality,LangChain\nintegrateswithnumerousexternalservices,suchasvectordatabases,APIproviders,",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 11,
      "page_label": "12"
    }
  },
  {
    "page_content": "tion.\nRisksAssociatedwithExternalProviders Toenhancefunctionality,LangChain\nintegrateswithnumerousexternalservices,suchasvectordatabases,APIproviders,\nand cloud storage platforms. However, these integrations expose applications to\nsecurity vulnerabilities:\n– Data Exposure: Accessing external resources can inadvertently expose sen-\nsitive data to third-party providers, a risk particularly relevant for applica-\ntions handling personal or confidential information. Without stringent data\nencryption and access control mechanisms, the potential for data leaks or\nunauthorized access increases.\n– Third-Party Dependency: Reliance on third-party services introduces de-\npendencies on their security protocols. Any compromise within a provider’s\ninfrastructurecouldaffectLangChainapplications,resultingindatabreaches\nor service interruptions. This underscores the importance of thoroughly vet-\nting providers and monitoring them for potential security issues.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 11,
      "page_label": "12"
    }
  },
  {
    "page_content": "LangChain 13\nLangChain’s security model addresses many of these concerns, yet challenges\npersist, particularly in sectors with rigorous compliance standards, such as fi-\nnance and healthcare. Key areas for ongoing improvement include:\n– DynamicPermissionAdjustment :CurrentpermissionsettingsinLangChain\nare defined at deployment, but in dynamic applications, permissions may\nneed to adapt based on user interactions. Implementing adaptive permis-\nsions responsive to application state or user roles could enhance security.\n– Advanced Encryption Standards: For applications processing highly\nsensitive data, adopting advanced encryption practices—such as end-to-end\nor field-level encryption—could bolster data security within even trusted\nenvironments.\n– Proactive Security Analytics: Integrating predictive analytics to pre-\nemptively identify risks could further secure applications. Machine learning\nmodels analyzing application logs could flag anomalous patterns indicative",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 12,
      "page_label": "13"
    }
  },
  {
    "page_content": "emptively identify risks could further secure applications. Machine learning\nmodels analyzing application logs could flag anomalous patterns indicative\nof potential breaches or misuse.\nIn summary, LangChain’s security framework includes robust features such\nas granular permissions, sandboxing, and real-time monitoring. While these mea-\nsures provide a solid foundation, the ongoing challenge of securing LLM-driven\napplications—particularly those relying on external providers—demands contin-\nued advancements in security practices.\n6 Conclusion\nLangChain significantly advances the development of applications powered by\nlarge language models (LLMs). Its modular framework—including components\nlike LangGraph for stateful process modeling, LangServe for scalable API de-\nployment, and LangSmith for monitoring and evaluation—enables developers to\nbuild scalable, context-aware applications tailored to specific needs across di-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 12,
      "page_label": "13"
    }
  },
  {
    "page_content": "ployment, and LangSmith for monitoring and evaluation—enables developers to\nbuild scalable, context-aware applications tailored to specific needs across di-\nverse domains, including NLP, cybersecurity, healthcare, finance, and customer\nservice.\nWhile its versatility extends beyond NLP, allowing for applications in fields\nlike cybersecurity (e.g., threat detection and automated incident response), the\nframework’s emphasis on flexibility introduces complexities that may present a\nlearning curve for developers new to LangChain. Additionally, reliance on exter-\nnal integrations raises important security considerations, such as data exposure\nand dependency vulnerabilities, which are critical in sensitive areas where data\nintegrity and privacy are paramount.\nIn summary, LangChain’s transformative potential lies in bridging the gap\nbetween the power of large language models and practical application develop-\nment across multiple fields. By balancing its robust capabilities with enhance-",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 12,
      "page_label": "13"
    }
  },
  {
    "page_content": "between the power of large language models and practical application develop-\nment across multiple fields. By balancing its robust capabilities with enhance-\nments in usability and security, LangChain can continue to serve as a valuable\ntool for developers seeking to leverage LLMs in building innovative and secure\napplications. As industries increasingly adopt AI technologies, frameworks like\nLangChain are poised to play a pivotal role in shaping the next generation of\nintelligent, scalable, and secure solutions across various sectors.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 12,
      "page_label": "13"
    }
  },
  {
    "page_content": "14 Vasilios Mavroudis\nReferences\n1. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Flo-\nrencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal\nAnadkat, et al. GPT-4 Technical Report.arXiv preprint arXiv:2303.08774, 2023.\n2. Harrison Chase. LangChain, Oct 2022. Available at https://github.com/\nlangchain-ai/langchain.\n3. LangChain, Inc. LangChain Documentation: Integration Providers. LangChain,\nInc.,SanFrancisco,CA,2024. Availableat https://python.langchain.com/docs/\nintegrations/providers/.\n4. LangChain, Inc. LangChain Documentation: Key Concepts. LangChain, Inc.,\nSan Francisco, CA, 2024. Available at https://python.langchain.com/docs/\nconcepts/.\n5. LangChain, Inc. LangChain Documentation: LangServe. LangChain, Inc.,\nSan Francisco, CA, 2024. Available at https://python.langchain.com/docs/\nlangserve/.\n6. LangChain, Inc. LangChain Documentation: Security Best Practices. LangChain,",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 13,
      "page_label": "14"
    }
  },
  {
    "page_content": "San Francisco, CA, 2024. Available at https://python.langchain.com/docs/\nlangserve/.\n6. LangChain, Inc. LangChain Documentation: Security Best Practices. LangChain,\nInc.,SanFrancisco,CA,2024. Availableat https://python.langchain.com/docs/\nsecurity/.\n7. LangChain, Inc.LangGraph: Building Language Agents as Graphs, 2024. Accessed:\n2024-11-04.\n8. LangChain, Inc.LangGraph Platform Documentation, 2024. Accessed: 2024-11-04.\n9. LangChain, Inc. LangSmith: A Developer Platform for LLM Applications, 2024.\nAccessed: 2024-11-04.\n10. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\nKarpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\ntäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks.\nAdvances in Neural Information Processing Systems, 33:9459–9474, 2020.\n11. Grzegorz Malewicz, Matthew H Austern, Aart JC Bik, James C Dehnert, Ilan\nHorn, Naty Leiser, and Grzegorz Czajkowski. Pregel: A System for Large-Scale",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 13,
      "page_label": "14"
    }
  },
  {
    "page_content": "11. Grzegorz Malewicz, Matthew H Austern, Aart JC Bik, James C Dehnert, Ilan\nHorn, Naty Leiser, and Grzegorz Czajkowski. Pregel: A System for Large-Scale\nGraph Processing. InProceedings of the 2010 ACM SIGMOD International Con-\nference on Management of Data, pages 135–146, 2010.\n12. OpenAI. Hello GPT-4O, 05 2024.\n13. OpenAI. Introducing OpenAI O1-Preview, 09 2024.\n14. Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui\nYu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican,\net al. Gemini: A Family of Highly Capable Multimodal Models.arXiv preprint\narXiv:2312.11805, 2023.\n15. The Apache Software Foundation.Apache Beam: An Advanced Unified Program-\nming Model, 2024. Accessed: 2024-11-04.\n16. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. LLaMA: Open and Efficient Foundation Language Models.arXiv",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 13,
      "page_label": "14"
    }
  },
  {
    "page_content": "Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. LLaMA: Open and Efficient Foundation Language Models.arXiv\npreprint arXiv:2302.13971, 2023.",
    "metadata": {
      "producer": "pdfTeX-1.40.26",
      "creator": "LaTeX with hyperref",
      "creationdate": "2024-11-06T10:08:55+00:00",
      "author": "",
      "keywords": "",
      "moddate": "2024-11-06T10:08:55+00:00",
      "ptex.fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0",
      "subject": "",
      "title": "",
      "trapped": "/False",
      "source": "/mnt/hdd/bini/nsk/rag-ai/data/inbox/langchain.pdf",
      "total_pages": 14,
      "page": 13,
      "page_label": "14"
    }
  },
  {
    "page_content": "3 | P a g e \n \nFile system \nFile concept  \n computers use various types of non-volatile storage devices (like HDDs, SSDs, \ntapes, etc.) to store data, and the operating system provides a consistent, logical \nview of this storage by using files. A file is a named collection of related \ninformation and is the smallest unit in which data can be stored on secondary \nstorage. Files can contain different types of data  such as text, programs, images, \nor system information  and their structure depends on the type of content. The \noperating system abstracts physical storage through the use of files, making data \nstorage and retrieval more manageable for users and applications \n \nFile attribute \nA file is identified by a human -readable name, making it easy for users to \nreference, regardless of who created or uses it. Once created, a file becomes \nindependent of its origin and can be copied or shared across systems while",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 0,
      "page_label": "1"
    }
  },
  {
    "page_content": "reference, regardless of who created or uses it. Once created, a file becomes \nindependent of its origin and can be copied or shared across systems while \nretaining its name. Additionally, files have various attributes such as name, type, \nlocation, size, access permissions, timestamps, and unique identifiers that help the \noperating system manage, protect, and track the file. Some modern file systems \nalso include extended attributes like character encoding and security features. \n \n✓ Name The symbolic file name is the only information kept in human \nreadable form. \n✓ Identifie This unique tag, usually a number, identifies the file within the file \nsystem it is the non-human-readable name for the file.   \n✓ Type This information is needed for systems that support different types of \nfiles.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 0,
      "page_label": "1"
    }
  },
  {
    "page_content": "4 | P a g e \n \n✓ Location This information is a pointer to a device and to the location of the \nfile on that device \n✓ Size The current size of the file (in bytes, words, or blocks) and possibly the \nmaximum allowed size are included in this attribute.  \n✓ Protection Access-control information determines who can do reading, \nwriting, executing, and so on.   \n✓ Timestamps and user identificatio n This information may be kept for \ncreation, last modification, and last use. These data can be useful for \nprotection, security, and usage monitoring.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 1,
      "page_label": "2"
    }
  },
  {
    "page_content": "5 | P a g e \n \nFile operation \n A file is an  abstract data type. To define a file properly, we need to \nconsider the operations that can be performed on files. The operating \nsystem can provide system calls to create, write, read, reposition, delete and \ntruncate files. \n \n▪ Creating a file Two steps are necessary to create a file. First, space in \nthe file system must be found for the file. Second, an entry for the new \nfile must be made in the directory. \n▪ Writing a file To write a file, we make a system call specifying both the \nname of the file and the information to be written to the file. Given \nthe name of the file the system searches the directory to find the file’s \nlocation. The system must keep a write pointer to the location in the \nfile where the next write is to take place. The write pointer must be \nupdated whenever a write occurs. \n▪ Reading a file To read from a file, we use a system call that specifies",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 2,
      "page_label": "3"
    }
  },
  {
    "page_content": "file where the next write is to take place. The write pointer must be \nupdated whenever a write occurs. \n▪ Reading a file To read from a file, we use a system call that specifies \nthe name of the file and where (in memory) the next block of the file \nshould be put. Again, the directory is searched for the associated \nentry, and the system needs to keep a read pointer to the loc ation in \nthe file where the next read is to take place. Once the read has taken \nplace, the read pointer is updated. Because a process is usually either \nreading from or writing to a file, the current operation location can be \nkept as a per-process current f ile-position pointer. Both the read and \nwrite operations use this same pointer, saving space and reducing \nsystem complexity. \n▪ Repositioning within a file  The directory is searched for the \nappropriate entry, and the current-file-position pointer is repositioned \nto a given value. Repositioning within a file need not involve any actual",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 2,
      "page_label": "3"
    }
  },
  {
    "page_content": "appropriate entry, and the current-file-position pointer is repositioned \nto a given value. Repositioning within a file need not involve any actual \nI/O. This file operation is also known as a file seek.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 2,
      "page_label": "3"
    }
  },
  {
    "page_content": "6 | P a g e \n \n▪ Deleting a file To delete a file, we search the directory for the named \nfile. Having found the associated directory entry, we release all file \nspace, so that it can be reused by other files, and erase the directory \nentry \n \n▪ Truncating a file The user may want to erase the contents of a file but \nkeep its attributes. Rather than forcing the user to delete the file and \nthen re  create it, this function allows all  attributes to remain \nunchanged—except for file length—but lets the file be reset to length \nzero and its file space released. \n \n▪ File pointer On systems that do not include a file offset as part of the \nread() and write() system calls, the system must track the last read \nwrite location as a current-file-position pointer. This pointer is unique \nto each  process operating on the file and therefore must be kept \nseparate from the on-disk file attributes. \n \n▪ File-open count As files are closed, the operating system must reuse",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 3,
      "page_label": "4"
    }
  },
  {
    "page_content": "to each  process operating on the file and therefore must be kept \nseparate from the on-disk file attributes. \n \n▪ File-open count As files are closed, the operating system must reuse \nits open -file table entries, or it could run out of space in the table. \nMultiple processes may have opened a file, and the system must wait \nfor the last file to close before removing the open-file table entry. The \nfile-open count tracks the number of opens and closes and reaches \nzero on the last close. The system can then remove the entry. \n▪ Disk location of the file Most file operations require the system to \nmodify data within the file. The information needed to locate the file \non disk is kept in memory so that the system does not have to read it \nfrom disk for each operation. \n▪ Access rights Each process opens a file in an access mode. This \ninformation is stored on the per  process table so the operating system \ncan allow or deny subsequent I/O requests.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 3,
      "page_label": "4"
    }
  },
  {
    "page_content": "7 | P a g e \n \nFile types  \nthe importance of file types  in operating systems and how they help the \nsystem and applications interact appropriately with files. A common way to \nindicate a file's type is by using a file extension  (e.g., .docx, .exe, .java). These \nextensions help identify what kind of file it is and what operations can be \nperformed on it. While some operating systems rely on extensions to recognize \nfile types, others treat them as hints for applications. Recognizing file types helps \nprevent errors, such as trying to read binary files as text, and allows programs to \nfind and work with the files they expect. \n \nFile structure \nfile types can define a file's internal structure , which is necessary for the \noperating system and applications to properly read and use the file. While \nsupporting multiple file structures can make the OS more functional, it also \nincreases complexity and size. To avoid this, many systems (like UNIX and",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 4,
      "page_label": "5"
    }
  },
  {
    "page_content": "supporting multiple file structures can make the OS more functional, it also \nincreases complexity and size. To avoid this, many systems (like UNIX and \nWindows) keep file structures minimal and treat files simply as byte sequences, \nleaving structure interpretation to applications. However, the OS must still \nrecognize certain essential file types, like executables, to function properly.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 4,
      "page_label": "5"
    }
  },
  {
    "page_content": "8 | P a g e \n \nInternal file structure \nManaging file data on disk involves dealing with differences between logical \ndata organization  and the physical storage structure  of disks. Disks perform \ninput/output operations in fixed-size units called blocks, which are determined by \nthe hardware’s sector size (e.g., 512 bytes per block). However, the logical records \nthat applications or users work with —such as lines of text or individual bytes —\noften do not align perfectly with these fixed block sizes. As a result, the operating \nsystem or application mus t pack multiple logical records into physical blocks  to \nmake efficient use of disk space and ensure correct data access. \nFor instance, UNIX treats files simply as streams of bytes, where each byte is \naddressable by its offset from the beginning of the file. This provides flexibility and \nsimplicity, allowing any program to access any part of a file without needing to",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 5,
      "page_label": "6"
    }
  },
  {
    "page_content": "addressable by its offset from the beginning of the file. This provides flexibility and \nsimplicity, allowing any program to access any part of a file without needing to \nworry ab out record boundaries. The operating system handles packing and \nunpacking of bytes into physical disk blocks behind the scenes, allowing \ndevelopers to focus on the logical structure of their data rather than physical disk \nlimitations. \nHowever, this method introduces internal fragmentation , where the last \nblock of a file may not be fully used. Since disk space is always allocated in whole \nblocks, any unused portion of the last block represents wasted space. For example, \nif a file is 1,949 bytes and the block size is 512 bytes, the system will allocate 2,048 \nbytes (four full blocks), leaving 99 bytes unused. This waste increases as block sizes \ngrow, creating a trade -off between larger block sizes (which may improve \nperformance) and efficiency of space usage.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 5,
      "page_label": "6"
    }
  },
  {
    "page_content": "grow, creating a trade -off between larger block sizes (which may improve \nperformance) and efficiency of space usage. \nthe operating system must bridge the gap between how data is logically \norganized and how it is physically stored. It does so by translating logical records \ninto physical blocks and managing the resulting overhead, such as internal \nfragmentation. While this  introduces some inefficiency, especially with larger \nblock sizes, it is a necessary part of making file systems practical and efficient for \na wide variety of applications and data types.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 5,
      "page_label": "6"
    }
  },
  {
    "page_content": "9 | P a g e \n \nAccess methods \nSequential access \n The simplest access method is sequential access. Information in the file is \nprocessed in order, one record after the other. This mode of access is by far the \nmost common; for example, editors and compilers usually access files in this \nfashion. \n Reads and writes make up the bulk of the operations on a file. A read \noperation—read next()  reads the next portion of the file and automatically \nadvances a file pointer, which tracks the I/O location. Similarly, the write operation \nwrite next() appends to the end of the file and advances to the end of the newly \nwritten material (the new end of file). Such a file can be reset to the beginning, \nand on  some systems a program may be able to skip forward or backward n \nrecords for some integer n perhaps only for n = 1. Sequential access,  \n \n \nSequential access file \nwhich is depicted in the Figure above is based on a tape model of a file and",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 6,
      "page_label": "7"
    }
  },
  {
    "page_content": "records for some integer n perhaps only for n = 1. Sequential access,  \n \n \nSequential access file \nwhich is depicted in the Figure above is based on a tape model of a file and \nworks as well on sequential-access devices as it does on random-access ones.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 6,
      "page_label": "7"
    }
  },
  {
    "page_content": "10 | P a g e \n \nDirect access \nthe direct-access (or relative access) method  for file systems, which allows \nprograms to read or write fixed -length records in any order, unlike sequential \naccess which processes data in a specific sequence. Direct access is especially \nuseful for applications like databases or reservation systems, where fast, random \naccess to specific records is essential. With this method, file operations are based \non block numbers that reference the position of data relative to the file’s start, \nrather than its physical location on disk. This abstraction gives the operating \nsystem flexibility in file placement and helps manage security. \nSome systems support only sequential or direct access, while others require \ndeclaring the access type when a file is created. Although sequential access can \nbe simulated on direct-access files easily, the reverse is inefficient. Overall, direct \naccess enhances performance for data -heavy applications that need quick,",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 7,
      "page_label": "8"
    }
  },
  {
    "page_content": "be simulated on direct-access files easily, the reverse is inefficient. Overall, direct \naccess enhances performance for data -heavy applications that need quick, \ntargeted retrieval of information.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 7,
      "page_label": "8"
    }
  },
  {
    "page_content": "11 | P a g e \n \nDirectory structure \n The directory can be viewed as a symbol table that translates file names into \ntheir file control blocks. If we take such a view, we see that the directory itself can \nbe organized in many ways. The organization must allow us to insert entries, to \ndelete entries, to search for a named entry, and t o list all the entries in the \ndirectory. When considering a particular directory structure we need to keep in \nmind the operations that are to be performed on a directory: \n• Search for a file We need to be able to search a directory structure to find  \nthe entry for a particular file. Since files have symbolic  names and similar \nnames may indicate a relationship among files, we may want to be able to \nfind all files whose names match a particular pattern. \n• Create a file New files need to be created and added to the directory. \n• Delete a file When a file is no longer needed we want to be able to remove",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 8,
      "page_label": "9"
    }
  },
  {
    "page_content": "• Create a file New files need to be created and added to the directory. \n• Delete a file When a file is no longer needed we want to be able to remove \nit from the directory. Note a delete leaves a hole in the directory structure \nand the file system may have a method to defragement  the directory \nstructure.  \n•  List a directory  We need to be able to list the files in a directory and the \ncontents of the directory entry for each file in the list. \n• Rename a file Because the name of a file represents its contents to its users, \nwe must be able to change the name when the contents or use of the file \nchanges. Renaming a file may also allow its position within the directory \nstructure to be changed.  \n• Traverse the file system We may wish to access every directory and every \nfile within a directory structure. For reliability, it is a good idea to save the \ncontents and structure of the entire file system at regular intervals. Often,",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 8,
      "page_label": "9"
    }
  },
  {
    "page_content": "file within a directory structure. For reliability, it is a good idea to save the \ncontents and structure of the entire file system at regular intervals. Often, \nwe do this by copying all files to magnetic tape other secondary storage or \nacross a network to another system or the cloud. This technique provides a \nbackup copy in case of system failure. In addition, if a file is no longer in use \nthe file can be copied the backup target and the disk space of that file \nreleased for reuse by another file.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 8,
      "page_label": "9"
    }
  },
  {
    "page_content": "12 | P a g e \n \nSingle level directory \n The simplest directory structure is the single -level directory. All files are \ncontained in the same directory, which is easy to support and understand A single-\nlevel directory has significant limitations, however, when the number of files \nincreases or when the system has more than one user. Since all fi les are in the \nsame directory, they must have unique names. If two users call their data file \ntest.txt, then the unique-name rule is violated \n \nSingle level directory \n \nTwo level directory \n As we have seen a single level directory often leads to confusion of file names \namong different users. But In a two-level directory structure  each user has a \nseparate User File Directory (UFD), and all UFDs are listed in a Master File Directory \n(MFD). This structure helps prevent filename conflicts between users but limits \ncollaboration, as it isolates user files. To allow access to another user's file, a user",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 9,
      "page_label": "10"
    }
  },
  {
    "page_content": "(MFD). This structure helps prevent filename conflicts between users but limits \ncollaboration, as it isolates user files. To allow access to another user's file, a user \nmust know the full path name  (e.g., /user b/test.txt), combining both the \nusername and filename. \nDifferent operating systems use different file naming conventions. For \nexample, Windows uses volume letters (C:\\user b\\test.txt), while UNIX/Linux uses \nhierarchical paths ( /u/pgalvin/test). Some systems (like OpenVMS) include \nvolume, directory, and version information in file names.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 9,
      "page_label": "10"
    }
  },
  {
    "page_content": "13 | P a g e \n \nFor system files (e.g., loaders or compilers), storing copies in every UFD is \ninefficient. Instead, a special directory stores these files, and the OS searches user \ndirectories first, then this system directory, based on a search path. The search \npath can be customized, allowing flexible file and command location resolution, \ncommonly seen in UNIX and Windows systems. \n \n        Two level directory structure \nTree structured directories \nA tree-structured directory extends the two-level directory into a hierarchy \nof arbitrary depth, allowing users to create subdirectories to organize files \nlogically. The structure starts with a root directory, and each file has a unique path \nname—either absolute (starting from root) or relative (from the current \ndirectory). \nEach process typically has a current directory, set at login and inherited by \nsubprocesses. Users can change this directory to access different files more easily.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 10,
      "page_label": "11"
    }
  },
  {
    "page_content": "directory). \nEach process typically has a current directory, set at login and inherited by \nsubprocesses. Users can change this directory to access different files more easily. \nDirectories are special files with entries marked as either files or \nsubdirectories, managed using system calls. This model provides flexibility, \nallowing logical grouping of files (e.g., separating source code and binaries). \nDeleting directories can follow two policies:",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 10,
      "page_label": "11"
    }
  },
  {
    "page_content": "14 | P a g e \n \n• Only allow deletion if empty, requiring manual file removal. \n• Recursive deletion, as in UNIX's rm -r, which removes all contents but risks \naccidental data loss. \nUsers can access other users' files by specifying full path names, supporting both \nfile organization and file sharing. \n  \nAcyclic graph directories \n An acyclic graph directory structure is an extension of the tree structure that \nallows file and directory sharing  across multiple locations in the file system \nwithout duplication. \n1. Purpose: Enables multiple users or directories to share the same file or \nsubdirectory, avoiding unnecessary duplication and ensuring changes are \nreflected everywhere. \n2. Structure: \no A tree prohibits sharing. \no An acyclic graph  (no cycles) allows files/subdirectories to exist in \nmultiple directories.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 11,
      "page_label": "12"
    }
  },
  {
    "page_content": "15 | P a g e \n \n3. Implementation Methods: \no Links (symbolic or hard) point to the actual file or directory. \n▪ Symbolic links (soft): Store the path to the original file; may break \nif the target is deleted. \n▪ Hard links: Share the same inode and use a reference count to \nmanage deletion. \no Duplicate entries (not recommended): Cause consistency issues when \na file is modified. \n4. Challenges: \no Multiple path names to the same file (aliasing problem). \no Traversal issues during backups or system scans. \no Deletion complications: \n▪ If one user deletes a file, others may be left with dangling \npointers. \n▪ Reference counting is used (as in UNIX) to delete a file only when \nall references are removed. \n5. Design Considerations: \no Some systems (for simplicity and safety) do not allow shared \ndirectories or links. \no Proper management of links and deletion policies is crucial to maintain \nfile system integrity.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 12,
      "page_label": "13"
    }
  },
  {
    "page_content": "o Some systems (for simplicity and safety) do not allow shared \ndirectories or links. \no Proper management of links and deletion policies is crucial to maintain \nfile system integrity. \nAn acyclic graph directory offers flexibility for sharing but adds complexity in \nmanaging references, updates, and deletions. Systems like UNIX manage this using \nreference counts and links while avoiding cycles to maintain structure.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 12,
      "page_label": "13"
    }
  },
  {
    "page_content": "16 | P a g e \n \n \nAcyclic-graph directory structure \n \nGeneral graph directory \nAn acyclic graph directory structure  is designed to allow file and directory \nsharing while avoiding cycles to maintain simplicity and performance. However, \nintroducing links can unintentionally create cycles, which cause serious issues. \n1. Acyclic vs. Cyclic Structure: \no A tree structure is naturally acyclic. \no Adding links can turn it into a graph, and if not managed carefully, \ncycles can form. \n2. Problems Caused by Cycles: \no Infinite loops during file searches or traversal due to re -entering the \nsame directories. \no Incorrect deletion handling because files in a cycle might still show non-\nzero reference counts even if they're no longer accessible.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 13,
      "page_label": "14"
    }
  },
  {
    "page_content": "17 | P a g e \n \n3. Garbage Collection Requirement: \no If cycles exist, reference counts alone are unreliable. \no Garbage collection (mark-and-sweep) is needed to identify and delete \nunreachable files. \no However, garbage collection is slow and rarely used  in disk -based \nsystems. \n4. Cycle Prevention Strategies: \no Use cycle detection algorithms (costly in disk-based graphs). \no A practical approach is to ignore links during traversal , which avoids \ncycles and overhead. \nTo keep directory management efficient and safe, acyclic structures are \npreferred. Allowing cycles introduces complexity, risks infinite loops, and \nnecessitates expensive garbage collection. Thus, systems must carefully prevent \ncycles when implementing file sharing via links. \n \nGeneral graph directory",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 14,
      "page_label": "15"
    }
  },
  {
    "page_content": "18 | P a g e \n \nProtection \n When information is stored in a computer system, we want to keep it safe \nfrom physical damage (the issue of reliability) and improper access (the issue of \nprotection). Reliability is generally provided  by duplicate copies of \nfiles.Manycomput ers have systems programs that automatically (or through \ncomputer-operator intervention) copy disk files to tape at regular intervals (once \nper day or week or month) to maintain a copy should a file system be accidentally \ndestroyed. File systems can be damaged by hardware problems (such as errors in \nreading or writing), power surgesor failures, head crashes, dirt, temperature \nextremes, and vandalism. Files may be deleted accidentally. Bugs in the file-system \nsoft ware can also cause file contents to be lost.  \nProtection can be provided in many ways. For a laptop system running a \nmodern operating system, we might provide protection by requiring a user",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 15,
      "page_label": "16"
    }
  },
  {
    "page_content": "soft ware can also cause file contents to be lost.  \nProtection can be provided in many ways. For a laptop system running a \nmodern operating system, we might provide protection by requiring a user \nnameandpasswordauthentication to access it, encrypting the secondary stor age \nso even someone opening the laptop and removing the drive would have a difficult \ntime accessing its data, and firewalling network access so that when it is in use it \nis difficult to break in via its network connection. In multiuser system, even valid \naccess of the system needs more advanced mechanisms to allow only valid access \nof the data. \n \nTypes of access \n The need to protect files is a direct result of the ability to access files. Systems \nthat do not permit access to the files of other users do not need protection. Thus, \nwecould providecomplete protection by prohibiting access. Alternatively, we \ncould provide free access with no protection. Both approaches are too extreme",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 15,
      "page_label": "16"
    }
  },
  {
    "page_content": "wecould providecomplete protection by prohibiting access. Alternatively, we \ncould provide free access with no protection. Both approaches are too extreme \nfor general use. What is needed is controlled access. Protection mechanisms \nprovide controlled access by limiting the types of f ile access that can be made. \nAccess is permitted or denied depending on several factors, one of which is the \ntype of access requested. Several different types of operations may be controlled:",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 15,
      "page_label": "16"
    }
  },
  {
    "page_content": "19 | P a g e \n \n➢ Read Read from the file. \n➢ Write Write or rewrite the file.  \n➢ Execute Load the file into memory and execute it.  \n➢ Append Write newinformation at the end of the file.  \n➢ Delete Delete the file and free its space for possible reuse.  \n➢ List List the name and attributes of the file. \n➢ Attribute change Changing the attributes of the file. \n \nAccess control \nThe main idea is that file and directory access in operating systems is \ncontrolled based on user identity, using Access Control Lists (ACLs) and simplified \nuser classifications (Owner, Group, Other) to manage permissions efficiently. \n1. Access Control Lists (ACLs): \no Each file/directory can have an ACL specifying which users have which \ntypes of access (read, write, execute). \no Offers fine-grained control but can be long and hard to manage. \n2. Simplified Access Scheme: \no Most systems simplify by using three user classes: \n▪ Owner: The file creator. \n▪ Group: A set of users with shared access.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 16,
      "page_label": "17"
    }
  },
  {
    "page_content": "2. Simplified Access Scheme: \no Most systems simplify by using three user classes: \n▪ Owner: The file creator. \n▪ Group: A set of users with shared access. \n▪ Other: All remaining users. \no Each class has read (r), write (w), and execute (x) permissions. \n3. Combining ACLs with User Classes: \no Modern systems like UNIX and Solaris  use the owner/group/other \nmodel by default, with ACLs added only when finer control is needed. \no Example: A project team can be a group, while temporary access for an \noutsider can be managed via ACLs.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 16,
      "page_label": "17"
    }
  },
  {
    "page_content": "20 | P a g e \n \n4. Implementation Details: \no UNIX: Uses 9 permission bits (rwx for each class), with optional ACLs \nindicated by a “+” sign in listings. \no Solaris: Uses commands like setfacl and getfacl. \no Windows: Uses a GUI to manage ACLs and permissions. \n5. Permission Conflicts: \no When ACLs and standard group permissions conflict, ACLs take \nprecedence, as they provide more specific rules. \nACLs provide flexible and detailed control over file access, while user \nclassifications (owner, group, other) simplify standard permission settings. Most \nsystems combine both approaches for efficiency and fine -tuned security, with \nACLs overriding default permissions when conflicts arise. \n \nOther protection approaches \n Another approach to the protection problem is to associate a password with \neach file. Just as access to the computer system is often controlled by a password \naccess to each file can be controlled in the same way. If the passwords are chosen",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 17,
      "page_label": "18"
    }
  },
  {
    "page_content": "each file. Just as access to the computer system is often controlled by a password \naccess to each file can be controlled in the same way. If the passwords are chosen \nrandomly and changed often, this scheme may be effective in limiting access to a \nfile. The use of passwords has a few disadvantages however. First, the number of \npasswords that a user needs to remember may become large, making the scheme \nimpractical. Second, if only one password is used  for all the files then once it is \ndiscovered all files are accessible protection is on an all -or-none basis. Some \nsystems allow a user to associate a password with a subdirectory rather than with \nan individual file to address this problem. In a multilevel directory structure, we \nneed to protect not only individual fi les but also collections of files in \nsubdirectories; that is, we need to provide a mechanism for directory protection. \nThe directory operations that must be protected are somewhat different from the",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 17,
      "page_label": "18"
    }
  },
  {
    "page_content": "subdirectories; that is, we need to provide a mechanism for directory protection. \nThe directory operations that must be protected are somewhat different from the \nfile operations. We want to control the creation and deletion of files in a directory. \nIn addition, we probably want to control whether a user can determine the",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 17,
      "page_label": "18"
    }
  },
  {
    "page_content": "21 | P a g e \n \nexistence of a file in a directory. Sometimes knowledge of the existence and name \nof a file is significant in itself.  \nThus, listing the contents of a directory must be a protected operation. \nSimilarly, if a path name refers to a file in a directory, the user must be allowed \naccess to both the directory and the file. In systems where files may have \nnumerous path names (such as acyclic and general graphs), a given user may \nhave different access rights to a particular file, depending on the path name \nused.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 18,
      "page_label": "19"
    }
  },
  {
    "page_content": "22 | P a g e \n \nMemory mapped files \n There is one other method of accessing files, and it is very commonly used. \nConsider a sequential read of a file on disk using the standard system calls open(), \nread(),andwrite(). Each file access requires a system call and disk access. \nAlternatively, we c an use the virtual memory techniques in to treat file I/O as \nroutine memory accesses. This approach, known as memory mapping a file, allows \na part of the virtual address space to be logically associated with the file. As we \nshall see, this can lead to significant performance increases. \n \nBasic mechanism \nMemory-mapped files are a powerful mechanism used by modern operating \nsystems to optimize file access and enable interprocess communication. Instead \nof reading and writing files through traditional system calls like read() and write(), \nmemory mapping allows a file to be directly mapped into the virtual memory",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 19,
      "page_label": "20"
    }
  },
  {
    "page_content": "of reading and writing files through traditional system calls like read() and write(), \nmemory mapping allows a file to be directly mapped into the virtual memory \nspace of a process. This approach not only improves performance by eliminating \nthe overhead of frequent system calls but also simplifies file manipulation by \ntreating file content as if it were part of the main memory. \nWhen a file is memory -mapped, the operating system links disk blocks to \npages in virtual memory. The first time a part of the file is accessed, a page fault \noccurs, prompting the OS to load that portion of the file from disk into a physical \nmemory page. Su bsequent accesses are handled like ordinary memory \noperations. Writes to the file, however, are not immediately saved to disk. Instead, \nthey are temporarily stored in memory and only written back to disk either when \nthe file is closed or under memory pressure, ensuring data is not lost.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 19,
      "page_label": "20"
    }
  },
  {
    "page_content": "they are temporarily stored in memory and only written back to disk either when \nthe file is closed or under memory pressure, ensuring data is not lost. \nDifferent operating systems implement memory mapping in different ways. \nFor instance, Solaris automatically memory-maps files, whether they are accessed \nthrough explicit memory -mapping system calls (like mmap()) or through \ntraditional file access methods. If accessed through standard system calls, Solaris \nmaps the file to the kernel address space, while memory-mapped files are placed \nin the process address space. In either case, the file I/O benefits from the speed \nand efficiency of memory operations.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 19,
      "page_label": "20"
    }
  },
  {
    "page_content": "23 | P a g e \n \nAn important advantage of memory -mapped files is their ability to enable \ndata sharing between processes. When multiple processes map the same file, they \nshare the same physical memory pages, so changes made by one process can be \ninstantly seen by the others. This sharing mechanism can be controlled using \nmutual exclusion methods to ensure consistency and sy nchronization. \nAdditionally, copy-on-write can be used to allow multiple processes to share read-\nonly access while creating separate memory copies if any  process attempts to \nmodify the data. \nBeyond file access, memory mapping also plays a vital role in interprocess \ncommunication (IPC). Shared memory segments are often created by memory -\nmapping files into the address space of communicating processes. This technique \nprovides an efficient way for processes to exchange information by reading and \nwriting to a common memory region without the need for slower I/O operations.",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 20,
      "page_label": "21"
    }
  },
  {
    "page_content": "provides an efficient way for processes to exchange information by reading and \nwriting to a common memory region without the need for slower I/O operations. \nmemory-mapped files streamline file access and enhance performance by \nreducing system call overhead and enabling direct memory manipulation. They \nalso provide a foundation for efficient shared memory, facilitating fast and simple \ncommunication between proc esses. By integrating file I/O and memory \nmanagement, memory mapping is a key feature in modern operating systems that \nsupports both performance optimization and process collaboration. \n \nShared memory in the window API \n The general outline for creating a region of shared memory using memory \nmappedfiles in the Windows API involves first creating a fil mapping for the file \nto be mapped and then establishing a view of the mapped file in a process’s \nvirtual address space. A second process can then open and create a view of the",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 20,
      "page_label": "21"
    }
  },
  {
    "page_content": "to be mapped and then establishing a view of the mapped file in a process’s \nvirtual address space. A second process can then open and create a view of the \nmapped file in its virtual address space. The mapped file represents the shared-\nmemory object that will enable communication to take place between the \nprocesses \n We next illustrate these steps in more detail. In this example, a producer \nprocess first creates a shared-memory object using the memory-mapping fea",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 20,
      "page_label": "21"
    }
  },
  {
    "page_content": "24 | P a g e \n \ntures available in the Windows API. The producer then writes a message to \nshared memory. After that a consumer process opens a mapping to the shared \nmemory object and reads the message written by the consumer \n             \n Memory mapped files                               shared memory using memory mapped I/O",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 21,
      "page_label": "22"
    }
  },
  {
    "page_content": "25 | P a g e \n \nReferences  \nOperating system concepts tenth edition by ABRAHAM SILBERSCHATZ, PETER \nBAER GALVIN, GREG GAGNE \nOperating system concepts ninth edition by ABRAHAM SILBERSCHATZ, PETER \nBAER GALVIN, GREG GAGNE \nModern operating system fourth edition by ANDREW S. TANENBAUM HERBERT \nBOS \ninternet",
    "metadata": {
      "producer": "iLovePDF",
      "creator": "PyPDF",
      "creationdate": "",
      "moddate": "2025-05-21T09:16:07+00:00",
      "source": "/mnt/hdd/bini/nsk/test-data/test.pdf",
      "total_pages": 23,
      "page": 22,
      "page_label": "23"
    }
  }
]